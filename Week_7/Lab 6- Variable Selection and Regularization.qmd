---
title: 'Lab 6'
format:
  html:
    embed-resources: true
execute:
  echo: true
code-fold: true
author: James Compagno
jupyter: python3
---


```{python}
import pandas as pd
import numpy as np
import plotnine as p9
from sklearn.pipeline import Pipeline
from sklearn.compose import make_column_selector, ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet 
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
```

# Dataset: Baseball Players

In this lab, we will use predictive modeling to design a model that predicts a baseball player's salary in a given year.

This dataset was originally taken from the StatLib library which is maintained at Carnegie Mellon University. This is part of the data that was used in the 1988 ASA Graphics Section Poster Session. The salary data were originally from Sports Illustrated, April 20, 1987. The 1986 and career statistics were obtained from The 1987 Baseball Encyclopedia Update published by Collier Books, Macmillan Publishing Company, New York.

**Format:** A data frame with 322 observations of major league players on the following 20 variables.

`AtBat` Number of times at bat in 1986 

`Hits` Number of hits in 1986 

`HmRun` Number of home runs in 1986

`Runs` Number of runs in 1986 

`RBI` Number of runs batted in in 1986 

`Walks` Number of walks in 1986 

`Years` Number of years in the major leagues 

`CAtBat` Number of times at bat during his career 

`CHits` Number of hits during his career 

`CHmRun` Number of home runs during his career 

`CRuns` Number of runs during his career 

`CRBI` Number of runs batted in during his career 

`CWalks` Number of walks during his career 

`League` A factor with levels A and N indicating player's league at the end of 1986 

`Division` A factor with levels E and W indicating player's division at the end of 1986 

`PutOuts` Number of put outs in 1986 

`Assists` Number of assists in 1986 

`Errors` Number of errors in 1986 

`Salary` 1987 annual salary on opening day in thousands of dollars 

`NewLeague` A factor with levels A and N indicating player's league at the beginning of 1987

You can download the dataset from [here](https://www.dropbox.com/s/boshaqfgdjiaxh4/Hitters.csv?dl=1).

A couple notes about this lab:

1.  Although it isn't listed as a specific question, don't forget to clean your data at the beginning. How will you handle missing data? Are there any variables that need adjusting?

2.  There are a **lot** of variables in the dataset! You may want to use the `remainder = "passthrough"` trick in your column transformers, rather than typing out a ton of gene names.

3.  Don't forget that in penalized regression, we **must** standardize our numeric variables.

4.  There is a lot of repetition in this lab. Think about ways to streamline your code - for example, you might consider writing simple functions to easily create pipelines.

```{python}
# Read the data
hitters = pd.read_csv("Hitters.csv")

# Remove rows with no value for salary 
hitters = hitters.dropna(subset=["Salary"])
hitters = hitters.reset_index(drop=True)

# Assign values
X = hitters.drop(columns=["Salary"])
y = hitters["Salary"]

# Train
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=67)

# Model Library 
model_library = {}
records = []
```

```{python}
hitters.head()
```

```{python}
# Column Transformer 
ct = ColumnTransformer(
    [
        ("standardize", 
         StandardScaler(), 
         make_column_selector(dtype_include=np.number)),
        ("cat", 
         OneHotEncoder(drop="first", sparse_output=False), 
         make_column_selector(dtype_include=object))
    ],
    remainder="passthrough",
    verbose_feature_names_out=False,
).set_output(transform="pandas")
```

# Part I: Different Model Specs

## A. Regression without regularization

1.  Create a pipeline that includes *all* the columns as predictors for `Salary`, and performs ordinary linear regression

2.  Fit this pipeline to the full dataset, and interpret a few of the most important coefficients.

3.  Use cross-validation to estimate the MSE you would expect if you used this pipeline to predict 1989 salaries.

```{python}
def run_linear_regression(model_name, features=None):
    """
    model_name - will be stored in model_library
    features - list or None
    Returns: DataFrame 
    """
    regression_type = "Linear"
    
    # Select features
    if features is not None:
        X_subset = X[features]
    else:
        X_subset = X
    
    # Cross Validation Pipeline
    pipe = Pipeline([
        ("preprocess", ct),
        ("linear_regression", LinearRegression())
    ])
    
    # Fit and add to Library
    pipe.fit(X_subset, y)
    model_library[model_name] = pipe
    
    # Get top 10 coefficients
    feature_names = pipe.named_steps['preprocess'].get_feature_names_out()
    coefficients = pipe.named_steps['linear_regression'].coef_
    
    coef_df = pd.DataFrame({
        'Variable': feature_names,
        'Coefficient': coefficients
    }).sort_values('Coefficient', key=abs, ascending=False).head(10)
    
    # Metrics Calculation 
    rmse = cross_val_score(pipe, X_subset, y, cv=5, scoring='neg_root_mean_squared_error')
    mse = cross_val_score(pipe, X_subset, y, cv=5, scoring='neg_mean_squared_error')
    r2 = cross_val_score(pipe, X_subset, y, cv=5, scoring='r2')
    
    # Metrics Storage 
    records.append({
        "Model": model_name,
        "Regression Type": regression_type,
        "Best Alpha": "NA", 
        "Best L1 Ratio": "NA",
        "Variables Used": len(X_subset.columns) if features else "All",
        "Top 10 Variables": ", ".join(coef_df['Variable'].head(10).tolist()),
        "Top 10 Coefficients": ", ".join([f"{c:.2f}" for c in coef_df['Coefficient'].head(10).tolist()]),
        "Split": "CV-5",
        "RMSE Mean": -rmse.mean(),
        "MSE Mean": -mse.mean(),
        "R2 Mean": r2.mean()
    })
    
    # Display
    cumulative_models = pd.DataFrame(records)
    return cumulative_models
```

```{python}
run_linear_regression("All_Features_Linear", None)
```

Interpretation: The top Coefficients for salary: CRuns (Career Runs), CAtBat (Career At-Bats), Hits (1986 Hits), etc. are what you would expec: more time playing = more mony. However some coefficients are negative, likely due to multicollinearity as a person who has more bats will have more hits who will have more runs. 

## B. Ridge regression

1.  Create a pipeline that includes *all* the columns as predictors for `Salary`, and performs ordinary ridge regression

2.  Use cross-validation to **tune** the $\lambda$ hyperparameter.

3.  Fit the pipeline with your chosen $\lambda$ to the full dataset, and interpret a few of the most important coefficients.

4.  Report the MSE you would expect if you used this pipeline to predict 1989 salaries.

```{python}
def run_ridge_regression(model_name, features=None):
    """
    model_name - will be stored in model_library
    features - list or None
    Returns: DataFrame 
    """
    regression_type = "Ridge"
    
    # Select features
    if features is not None:
        X_subset = X[features]
    else:
        X_subset = X
    
    # Pipeline with Ridge
    pipe = Pipeline([
        ("preprocess", ct),
        ("ridge", Ridge())
    ])
    
    # GridSearchCV 
    param_grid = {'ridge__alpha': np.logspace(-1, 2, 50)}
    gscv = GridSearchCV(pipe, param_grid, cv=5, scoring='neg_mean_squared_error')
    gscv.fit(X_subset, y)
    
    # Add best model to Library
    model_library[model_name] = gscv.best_estimator_
    
    # Get best alpha
    best_alpha = gscv.best_params_['ridge__alpha']
    
    # Get top 10 coefficients
    coef_df = pd.DataFrame({
        'Variable': gscv.best_estimator_.named_steps['preprocess'].get_feature_names_out(),
        'Coefficient': gscv.best_estimator_.named_steps['ridge'].coef_
    }).sort_values('Coefficient', key=abs, ascending=False).head(10)
    
    # Store coefficients in model library
    model_library[f"{model_name}_coefficients"] = coef_df
    
    # Metrics Calculation using best model
    rmse = cross_val_score(gscv.best_estimator_, X_subset, y, cv=5, scoring='neg_root_mean_squared_error')
    mse = cross_val_score(gscv.best_estimator_, X_subset, y, cv=5, scoring='neg_mean_squared_error')
    r2 = cross_val_score(gscv.best_estimator_, X_subset, y, cv=5, scoring='r2')
    
    # Metrics Storage 
    records.append({
        "Model": model_name,
        "Regression Type": regression_type,
        "Best Alpha": best_alpha, 
        "Best L1 Ratio": "NA",
        "Variables Used": len(X_subset.columns) if features else "All",
        "Top 10 Variables": ", ".join(coef_df['Variable'].head(10).tolist()),
        "Top 10 Coefficients": ", ".join([f"{c:.2f}" for c in coef_df['Coefficient'].head(10).tolist()]),
        "Split": "CV-5",
        "RMSE Mean": -rmse.mean(),
        "MSE Mean": -mse.mean(),
        "R2 Mean": r2.mean()
    })
    
    # Display
    cumulative_models = pd.DataFrame(records)
    return cumulative_models
```

```{python}
run_ridge_regression("Ridge_All_Tuned", None)
```

Interpretation: The coefficients for ridge regression were very similar to normal linear but in a different order and the coefficient number are smaller.. There is still an issue with multicollinearity 

## C. Lasso Regression

1.  Create a pipeline that includes *all* the columns as predictors for `Salary`, and performs ordinary ridge regression

2.  Use cross-validation to **tune** the $\lambda$ hyperparameter.

3.  Fit the pipeline with your chosen $\lambda$ to the full dataset, and interpret a few of the most important coefficients.

4.  Report the MSE you would expect if you used this pipeline to predict 1989 salaries.

```{python}
def run_lasso_regression(model_name, features=None):
    """
    model_name - will be stored in model_library
    features - list or None
    Returns: DataFrame 
    """
    regression_type = "Lasso"
    
    # Select features
    if features is not None:
        X_subset = X[features]
    else:
        X_subset = X
    
    # Pipeline with Lasso
    pipe = Pipeline([
        ("preprocess", ct),
        ("lasso", Lasso())
    ])
    
    # GridSearchCV to tune alpha
    param_grid = {'lasso__alpha': np.logspace(-1, 2, 50)}
    gscv = GridSearchCV(pipe, param_grid, cv=5, scoring='neg_mean_squared_error')
    gscv.fit(X_subset, y)
    
    # Add best model to Library
    model_library[model_name] = gscv.best_estimator_
    
    # Get best alpha
    best_alpha = gscv.best_params_['lasso__alpha']
    
    # Get top 10 coefficients
    coef_df = pd.DataFrame({
        'Variable': gscv.best_estimator_.named_steps['preprocess'].get_feature_names_out(),
        'Coefficient': gscv.best_estimator_.named_steps['lasso'].coef_
    }).sort_values('Coefficient', key=abs, ascending=False).head(10)
    
    # Store coefficients in model library
    model_library[f"{model_name}_coefficients"] = coef_df
    
    # Metrics Calculation using best model
    rmse = cross_val_score(gscv.best_estimator_, X_subset, y, cv=5, scoring='neg_root_mean_squared_error')
    mse = cross_val_score(gscv.best_estimator_, X_subset, y, cv=5, scoring='neg_mean_squared_error')
    r2 = cross_val_score(gscv.best_estimator_, X_subset, y, cv=5, scoring='r2')
    
    # Metrics Storage 
    records.append({
        "Model": model_name,
        "Regression Type": regression_type,
        "Best Alpha": best_alpha, 
        "Best L1 Ratio": "NA",
        "Variables Used": len(X_subset.columns) if features else "All",
        "Top 10 Variables": ", ".join(coef_df['Variable'].head(10).tolist()),
        "Top 10 Coefficients": ", ".join([f"{c:.2f}" for c in coef_df['Coefficient'].head(10).tolist()]),
        "Split": "CV-5",
        "RMSE Mean": -rmse.mean(),
        "MSE Mean": -mse.mean(),
        "R2 Mean": r2.mean()
    })
    
    # Display
    cumulative_models = pd.DataFrame(records)
    return cumulative_models
```

```{python}
run_lasso_regression("Lasso_All_Tuned", None)
```

## D. Elastic Net

1.  Create a pipeline that includes *all* the columns as predictors for `Salary`, and performs ordinary ridge regression

2.  Use cross-validation to **tune** the $\lambda$ and $\alpha$ hyperparameters.

3.  Fit the pipeline with your chosen hyperparameters to the full dataset, and interpret a few of the most important coefficients.

4.  Report the MSE you would expect if you used this pipeline to predict 1989 salaries.

```{python}
def run_elasticnet_regression(model_name, features=None):
    """
    model_name - will be stored in model_library
    features - list or None
    Returns: DataFrame 
    """
    regression_type = "ElasticNet"
    
    # Select features
    if features is not None:
        X_subset = X[features]
    else:
        X_subset = X
    
    # Pipeline with ElasticNet
    pipe = Pipeline([
        ("preprocess", ct),
        ("elasticnet", ElasticNet())
    ])
    
    # GridSearchCV to tune alpha and l1_ratio
    param_grid = {
        'elasticnet__alpha': np.logspace(-1, 2, 50),
        'elasticnet__l1_ratio': [0, 0.25, 0.5, 0.75, 1]
    }
    gscv = GridSearchCV(pipe, param_grid, cv=5, scoring='neg_mean_squared_error')
    gscv.fit(X_subset, y)
    
    # Add best model to Library
    model_library[model_name] = gscv.best_estimator_
    
    # Get best hyperparameters
    best_alpha = gscv.best_params_['elasticnet__alpha']
    best_l1_ratio = gscv.best_params_['elasticnet__l1_ratio']
    
    # Get top 10 coefficients
    coef_df = pd.DataFrame({
        'Variable': gscv.best_estimator_.named_steps['preprocess'].get_feature_names_out(),
        'Coefficient': gscv.best_estimator_.named_steps['elasticnet'].coef_
    }).sort_values('Coefficient', key=abs, ascending=False).head(10)
    
    # Store coefficients in model library
    model_library[f"{model_name}_coefficients"] = coef_df
    
    # Metrics Calculation using best model
    rmse = cross_val_score(gscv.best_estimator_, X_subset, y, cv=5, scoring='neg_root_mean_squared_error')
    mse = cross_val_score(gscv.best_estimator_, X_subset, y, cv=5, scoring='neg_mean_squared_error')
    r2 = cross_val_score(gscv.best_estimator_, X_subset, y, cv=5, scoring='r2')
    
    # Metrics Storage 
    records.append({
        "Model": model_name,
        "Regression Type": regression_type,
        "Best Alpha": best_alpha, 
        "Best L1 Ratio": best_l1_ratio,
        "Variables Used": len(X_subset.columns) if features else "All",
        "Top 10 Variables": ", ".join(coef_df['Variable'].head(10).tolist()),
        "Top 10 Coefficients": ", ".join([f"{c:.2f}" for c in coef_df['Coefficient'].head(10).tolist()]),
        "Split": "CV-5",
        "RMSE Mean": -rmse.mean(),
        "MSE Mean": -mse.mean(),
        "R2 Mean": r2.mean()
    })
    
    # Display
    cumulative_models = pd.DataFrame(records)
    return cumulative_models
```

```{python}
run_elasticnet_regression("ElasticNet_All_Tuned",None)
```

# Part II. Variable Selection

Based on the above results, decide on:

-   Which *numeric* variable is most important: 

        Hits

-   Which *five* numeric variables are most important:

        1. CRuns
        2. Hits
        3. AtBat
        4. CRBI
        5. CWalks

-   Which *categorical* variable is most important: 
        
        Division_W

For **each** of the four model specifications, compare the following possible feature sets:

Report which combination of features and model performed best, based on the validation metric of MSE.

(Note: $\lambda$ and $\alpha$ must be re-tuned for each feature set.)

## 1.  Using only the one best numeric variable.

```{python}
run_linear_regression("Hits_Linear", features=['Hits'])
```

```{python}
run_ridge_regression("Hits_Ridge", features=['Hits'])
```

```{python}
run_lasso_regression("Hits_Lasso", features=['Hits'])
```

```{python}
run_elasticnet_regression("Hits_Elasticnet", features=['Hits'])
```

### Interpretation 

They were all roughly the same but Elastcicnet did the best in the MSE department 

## 2.  Using only the five best variables.

```{python}
run_linear_regression("Top5_Linear", features=['CRuns', 'Hits', 'AtBat', 'CRBI', 'CWalks'])
```

```{python}
run_ridge_regression("Top5_Ridge", features=['CRuns', 'Hits', 'AtBat', 'CRBI', 'CWalks'])
```

```{python}
run_lasso_regression("Top5_Lasso", features=['CRuns', 'Hits', 'AtBat', 'CRBI', 'CWalks'])
```

```{python}
run_elasticnet_regression("Top5_Elasticnet", features=['CRuns', 'Hits', 'AtBat', 'CRBI', 'CWalks'])
```

### Interpretation 

In this case Ridge took the lead but not by much all the MSEs are not too different between the models 

## 3.  Using the five best numeric variables *and* their interactions with the one best categorical variable.

### Linear Model

```{python}
# Model Name
model_name = "Lin_Num_Cat_Interact"
regression_type = "Linear"  

# Features
numeric_vars = ['CRuns', 'Hits', 'AtBat', 'CRBI', 'CWalks']
cat_var = 'Division'

# Select and Subset
X_subset = X[numeric_vars + [cat_var]].copy()
X_subset['Division_Binary'] = (X_subset['Division'] == 'W').astype(int)

# Create interaction
X_subset['CRuns_x_Division'] = X_subset['CRuns'] * X_subset['Division_Binary']
X_subset['Hits_x_Division'] = X_subset['Hits'] * X_subset['Division_Binary']
X_subset['AtBat_x_Division'] = X_subset['AtBat'] * X_subset['Division_Binary']
X_subset['CRBI_x_Division'] = X_subset['CRBI'] * X_subset['Division_Binary']
X_subset['CWalks_x_Division'] = X_subset['CWalks'] * X_subset['Division_Binary']

# Drop the temporary Division_Binary column
X_subset = X_subset.drop(columns=['Division_Binary'])

# Pipeline 
pipe = Pipeline([
    ("preprocess", ct),
    ("linear_regression", LinearRegression())
])

# Fit and add to Library
pipe.fit(X_subset, y)
model_library[model_name] = pipe

# Get top 10 coefficients
feature_names = pipe.named_steps['preprocess'].get_feature_names_out()
coefficients = pipe.named_steps['linear_regression'].coef_

coef_df = pd.DataFrame({
    'Variable': feature_names,
    'Coefficient': coefficients
}).sort_values('Coefficient', key=abs, ascending=False).head(10)

# Metrics Calculation 
rmse = cross_val_score(pipe, X_subset, y, cv=5, scoring='neg_root_mean_squared_error')
mse = cross_val_score(pipe, X_subset, y, cv=5, scoring='neg_mean_squared_error')
r2 = cross_val_score(pipe, X_subset, y, cv=5, scoring='r2')

# Metrics Storage 
records.append({
    "Model": model_name,
    "Regression Type": regression_type,
    "Best Alpha": "NA", 
    "Best L1 Ratio": "NA",
    "Variables Used": len(X_subset.columns),
    "Top 10 Variables": ", ".join(coef_df['Variable'].head(10).tolist()),
    "Top 10 Coefficients": ", ".join([f"{c:.2f}" for c in coef_df['Coefficient'].head(10).tolist()]),
    "Split": "CV-5",
    "RMSE Mean": -rmse.mean(),
    "MSE Mean": -mse.mean(),
    "R2 Mean": r2.mean()
})

# Display
cumulative_models = pd.DataFrame(records)
cumulative_models
```

### Ridge Model

```{python}
# Model Name
model_name = "Ridge_Num_Cat_Interact"
regression_type = "Ridge"  

# Features
numeric_vars = ['CRuns', 'Hits', 'AtBat', 'CRBI', 'CWalks']
cat_var = 'Division'

# Select and Subset
X_subset = X[numeric_vars + [cat_var]].copy()
X_subset['Division_Binary'] = (X_subset['Division'] == 'W').astype(int)

# Create interaction
X_subset['CRuns_x_Division'] = X_subset['CRuns'] * X_subset['Division_Binary']
X_subset['Hits_x_Division'] = X_subset['Hits'] * X_subset['Division_Binary']
X_subset['AtBat_x_Division'] = X_subset['AtBat'] * X_subset['Division_Binary']
X_subset['CRBI_x_Division'] = X_subset['CRBI'] * X_subset['Division_Binary']
X_subset['CWalks_x_Division'] = X_subset['CWalks'] * X_subset['Division_Binary']

# Drop the temporary Division_Binary column
X_subset = X_subset.drop(columns=['Division_Binary'])

# Pipeline with Ridge
pipe = Pipeline([
    ("preprocess", ct),
    ("ridge", Ridge())  
])

# GridSearchCV 
param_grid = {'ridge__alpha': np.logspace(-1, 2, 50)}
gscv = GridSearchCV(pipe, param_grid, cv=5, scoring='neg_mean_squared_error')
gscv.fit(X_subset, y)

# Add best model to Library
model_library[model_name] = gscv.best_estimator_

# Get best alpha
best_alpha = gscv.best_params_['ridge__alpha']

# Get top 10 coefficients
feature_names = gscv.best_estimator_.named_steps['preprocess'].get_feature_names_out()
coefficients = gscv.best_estimator_.named_steps['ridge'].coef_

coef_df = pd.DataFrame({
    'Variable': feature_names,
    'Coefficient': coefficients
}).sort_values('Coefficient', key=abs, ascending=False).head(10)

# Metrics Calculation using best model
rmse = cross_val_score(gscv.best_estimator_, X_subset, y, cv=5, scoring='neg_root_mean_squared_error')
mse = cross_val_score(gscv.best_estimator_, X_subset, y, cv=5, scoring='neg_mean_squared_error')
r2 = cross_val_score(gscv.best_estimator_, X_subset, y, cv=5, scoring='r2')

# Metrics Storage 
records.append({
    "Model": model_name,
    "Regression Type": regression_type,
    "Best Alpha": best_alpha, 
    "Best L1 Ratio": "NA",
    "Variables Used": len(X_subset.columns),
    "Top 10 Variables": ", ".join(coef_df['Variable'].head(10).tolist()),
    "Top 10 Coefficients": ", ".join([f"{c:.2f}" for c in coef_df['Coefficient'].head(10).tolist()]),
    "Split": "CV-5",
    "RMSE Mean": -rmse.mean(),
    "MSE Mean": -mse.mean(),
    "R2 Mean": r2.mean()
})

# Display
cumulative_models = pd.DataFrame(records)
cumulative_models
```

### Lasso Model

```{python}
# Model Name
model_name = "Lasso_Num_Cat_Interact"
regression_type = "Lasso"  

# Features
numeric_vars = ['CRuns', 'Hits', 'AtBat', 'CRBI', 'CWalks']
cat_var = 'Division'

# Select and Subset
X_subset = X[numeric_vars + [cat_var]].copy()
X_subset['Division_Binary'] = (X_subset['Division'] == 'W').astype(int)

# Create interaction
X_subset['CRuns_x_Division'] = X_subset['CRuns'] * X_subset['Division_Binary']
X_subset['Hits_x_Division'] = X_subset['Hits'] * X_subset['Division_Binary']
X_subset['AtBat_x_Division'] = X_subset['AtBat'] * X_subset['Division_Binary']
X_subset['CRBI_x_Division'] = X_subset['CRBI'] * X_subset['Division_Binary']
X_subset['CWalks_x_Division'] = X_subset['CWalks'] * X_subset['Division_Binary']

# Drop the temporary Division_Binary column
X_subset = X_subset.drop(columns=['Division_Binary'])

# Pipeline
pipe = Pipeline([
    ("preprocess", ct),
    ("lasso", Lasso()) 
])

# GridSearchCV 
param_grid = {'lasso__alpha': np.logspace(-1, 2, 50)} 
gscv = GridSearchCV(pipe, param_grid, cv=5, scoring='neg_mean_squared_error')
gscv.fit(X_subset, y)

# Add best model to Library
model_library[model_name] = gscv.best_estimator_

# Get best alpha
best_alpha = gscv.best_params_['lasso__alpha']

# Get top 10 coefficients
feature_names = gscv.best_estimator_.named_steps['preprocess'].get_feature_names_out()
coefficients = gscv.best_estimator_.named_steps['lasso'].coef_

coef_df = pd.DataFrame({
    'Variable': feature_names,
    'Coefficient': coefficients
}).sort_values('Coefficient', key=abs, ascending=False).head(10)

# Metrics Calculation using best model
rmse = cross_val_score(gscv.best_estimator_, X_subset, y, cv=5, scoring='neg_root_mean_squared_error')
mse = cross_val_score(gscv.best_estimator_, X_subset, y, cv=5, scoring='neg_mean_squared_error')
r2 = cross_val_score(gscv.best_estimator_, X_subset, y, cv=5, scoring='r2')

# Metrics Storage 
records.append({
    "Model": model_name,
    "Regression Type": regression_type,
    "Best Alpha": best_alpha, 
    "Best L1 Ratio": "NA",
    "Variables Used": len(X_subset.columns),
    "Top 10 Variables": ", ".join(coef_df['Variable'].head(10).tolist()),
    "Top 10 Coefficients": ", ".join([f"{c:.2f}" for c in coef_df['Coefficient'].head(10).tolist()]),
    "Split": "CV-5",
    "RMSE Mean": -rmse.mean(),
    "MSE Mean": -mse.mean(),
    "R2 Mean": r2.mean()
})

# Display
cumulative_models = pd.DataFrame(records)
cumulative_models
```

### Elasticnet Model

```{python}
# Model Name
model_name = "ElasticNet_Num_Cat_Interact"  
regression_type = "ElasticNet" 

# Features
numeric_vars = ['CRuns', 'Hits', 'AtBat', 'CRBI', 'CWalks']
cat_var = 'Division'

# Select and Subset
X_subset = X[numeric_vars + [cat_var]].copy()
X_subset['Division_Binary'] = (X_subset['Division'] == 'W').astype(int)

# Create interaction
X_subset['CRuns_x_Division'] = X_subset['CRuns'] * X_subset['Division_Binary']
X_subset['Hits_x_Division'] = X_subset['Hits'] * X_subset['Division_Binary']
X_subset['AtBat_x_Division'] = X_subset['AtBat'] * X_subset['Division_Binary']
X_subset['CRBI_x_Division'] = X_subset['CRBI'] * X_subset['Division_Binary']
X_subset['CWalks_x_Division'] = X_subset['CWalks'] * X_subset['Division_Binary']

# Drop the temporary Division_Binary column
X_subset = X_subset.drop(columns=['Division_Binary'])

# Pipeline with ElasticNet
pipe = Pipeline([
    ("preprocess", ct),
    ("elasticnet", ElasticNet()) 
])

# GridSearchCV 
param_grid = {
    'elasticnet__alpha': np.logspace(-1, 2, 50),
    'elasticnet__l1_ratio': [0, 0.25, 0.5, 0.75, 1]
} 
gscv = GridSearchCV(pipe, param_grid, cv=5, scoring='neg_mean_squared_error')
gscv.fit(X_subset, y)

# Add best model to Library
model_library[model_name] = gscv.best_estimator_

# Get best Alpha and L1
best_alpha = gscv.best_params_['elasticnet__alpha'] 
best_l1_ratio = gscv.best_params_['elasticnet__l1_ratio'] 

# Get top 10 coefficients
feature_names = gscv.best_estimator_.named_steps['preprocess'].get_feature_names_out()
coefficients = gscv.best_estimator_.named_steps['elasticnet'].coef_

coef_df = pd.DataFrame({
    'Variable': feature_names,
    'Coefficient': coefficients
}).sort_values('Coefficient', key=abs, ascending=False).head(10)

# Metrics Calculation using best model
rmse = cross_val_score(gscv.best_estimator_, X_subset, y, cv=5, scoring='neg_root_mean_squared_error')
mse = cross_val_score(gscv.best_estimator_, X_subset, y, cv=5, scoring='neg_mean_squared_error')
r2 = cross_val_score(gscv.best_estimator_, X_subset, y, cv=5, scoring='r2')

# Metrics Storage 
records.append({
    "Model": model_name,
    "Regression Type": regression_type,
    "Best Alpha": best_alpha,
    "Best L1 Ratio": best_l1_ratio,
    "Variables Used": len(X_subset.columns),
    "Top 10 Variables": ", ".join(coef_df['Variable'].head(10).tolist()),
    "Top 10 Coefficients": ", ".join([f"{c:.2f}" for c in coef_df['Coefficient'].head(10).tolist()]),
    "Split": "CV-5",
    "RMSE Mean": -rmse.mean(),
    "MSE Mean": -mse.mean(),
    "R2 Mean": r2.mean()
})

# Display
cumulative_models = pd.DataFrame(records)
cumulative_models
```

### Interpretation 

Elastic Net Takes the lead again 

# Part III. Discussion

## A. Ridge

Compare your Ridge models with your ordinary regression models. How did your coefficients compare? Why does this make sense?

```{python}
cumulative_models[cumulative_models['Regression Type'].isin(['Linear', 'Ridge'])].sort_values('Regression Type')
```

Coefficients for Ridge models are on a whole smaller than the linear regression models 

## B. LASSO

Compare your LASSO model in I with your three LASSO models in II. Did you get the same $\lambda$ results? Why does this make sense? Did you get the same MSEs? Why does this make sense?

```{python}
cumulative_models[cumulative_models['Regression Type'] == 'Lasso']
```

While the latter Lasso models are not more than 10 Alpha units differengt than the First Lasso I would comfortably say they are all different. This makes sense as changing the number of features considered will impact alpha. The higher the features the lower the MSE as well. 

## C. Elastic Net

Compare your MSEs for the Elastic Net models with those for the Ridge and LASSO models. Why does it make sense that Elastic Net always "wins"?

```{python}
cumulative_models[cumulative_models['Regression Type'].isin(['ElasticNet', 'Ridge', 'Lasso'])].sort_values('Regression Type')
```

Elastic Net makes sense in that it won because it was more tuned than the other model as both Alpha and L1 were tested 

# Part IV: Final Model

Fit your final best pipeline on the full dataset, and summarize your results in a few short sentences and a plot.

"Best" is chosen by lowest MSE Mean

```{python}
cumulative_models.sort_values('R2 Mean', ascending=False).head(1)
```

```{python}
# Features
numeric_vars = ['CRuns', 'Hits', 'AtBat', 'CRBI', 'CWalks']
cat_var = 'Division'

# Select and Subset
X_final = X[numeric_vars + [cat_var]].copy()
X_final['Division_Binary'] = (X_final['Division'] == 'W').astype(int)

# Create interaction
X_final['CRuns_x_Division'] = X_final['CRuns'] * X_final['Division_Binary']
X_final['Hits_x_Division'] = X_final['Hits'] * X_final['Division_Binary']
X_final['AtBat_x_Division'] = X_final['AtBat'] * X_final['Division_Binary']
X_final['CRBI_x_Division'] = X_final['CRBI'] * X_final['Division_Binary']
X_final['CWalks_x_Division'] = X_final['CWalks'] * X_final['Division_Binary']

# Drop temporary column
X_final = X_final.drop(columns=['Division_Binary'])

# Fit the model 
best_pipe = model_library["Ridge_Num_Cat_Interact"]
best_pipe.fit(X_final, y)

# Generate predictions
y_pred = best_pipe.predict(X_final)

print("Final Model: Ridge_Num_Cat_Interact")
print(f"R² Score: {best_pipe.score(X_final, y):f}")
print(f"MSE: {((y - y_pred)**2).mean():f}")
```

```{python}
# Prepare data for plotting
df_plot = pd.DataFrame({
    'Actual_Salary': y,
    'Predicted_Salary': y_pred,
    'Division': X['Division']
})

# Create the plot
final_plot = (
    p9.ggplot(df_plot, p9.aes(x='Actual_Salary', y='Predicted_Salary'))
    + p9.geom_point(p9.aes(color='Division'), alpha=0.6, size=2)
    + p9.geom_abline(intercept=0, slope=1, color='red', linetype='dashed', size=1)
    + p9.labs(
        title='Ridge Regression: Predicted vs Actual Salary (with Interactions)',
        x='Actual Salary (thousands)',
        y='Predicted Salary (thousands)'
    )
    + p9.scale_color_manual(values=['#1f77b4', '#ff7f0e'])
    + p9.theme_minimal()
    + p9.theme(figure_size=(8, 6))
)

final_plot
```

While visually the regression line seems to decently represent the data the final R² Score: 0.462072 shows that there is a lot of room left for improvement. Likely this model would benefit from further exploration of quadraic, exponential, or log models. 

