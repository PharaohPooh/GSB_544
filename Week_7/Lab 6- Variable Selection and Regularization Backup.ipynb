{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf076df5",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Lab 6: Variable Selection and Regularization\"\n",
    "format: \n",
    "  html:\n",
    "    embed-resources: true\n",
    "execute:\n",
    "  echo: true\n",
    "code-fold: true\n",
    "author: James Compagno\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "2c0eb4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotnine as p9\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import make_column_selector, ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet \n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbceb24",
   "metadata": {},
   "source": [
    "# Dataset: Baseball Players\n",
    "\n",
    "In this lab, we will use predictive modeling to design a model that predicts a baseball player's salary in a given year.\n",
    "\n",
    "This dataset was originally taken from the StatLib library which is maintained at Carnegie Mellon University. This is part of the data that was used in the 1988 ASA Graphics Section Poster Session. The salary data were originally from Sports Illustrated, April 20, 1987. The 1986 and career statistics were obtained from The 1987 Baseball Encyclopedia Update published by Collier Books, Macmillan Publishing Company, New York.\n",
    "\n",
    "**Format:** A data frame with 322 observations of major league players on the following 20 variables.\n",
    "\n",
    "`AtBat` Number of times at bat in 1986 \n",
    "\n",
    "`Hits` Number of hits in 1986 \n",
    "\n",
    "`HmRun` Number of home runs in 1986\n",
    "\n",
    "`Runs` Number of runs in 1986 \n",
    "\n",
    "`RBI` Number of runs batted in in 1986 \n",
    "\n",
    "`Walks` Number of walks in 1986 \n",
    "\n",
    "`Years` Number of years in the major leagues \n",
    "\n",
    "`CAtBat` Number of times at bat during his career \n",
    "\n",
    "`CHits` Number of hits during his career \n",
    "\n",
    "`CHmRun` Number of home runs during his career \n",
    "\n",
    "`CRuns` Number of runs during his career \n",
    "\n",
    "`CRBI` Number of runs batted in during his career \n",
    "\n",
    "`CWalks` Number of walks during his career \n",
    "\n",
    "`League` A factor with levels A and N indicating player's league at the end of 1986 \n",
    "\n",
    "`Division` A factor with levels E and W indicating player's division at the end of 1986 \n",
    "\n",
    "`PutOuts` Number of put outs in 1986 \n",
    "\n",
    "`Assists` Number of assists in 1986 \n",
    "\n",
    "`Errors` Number of errors in 1986 \n",
    "\n",
    "`Salary` 1987 annual salary on opening day in thousands of dollars \n",
    "\n",
    "`NewLeague` A factor with levels A and N indicating player's league at the beginning of 1987\n",
    "\n",
    "You can download the dataset from [here](https://www.dropbox.com/s/boshaqfgdjiaxh4/Hitters.csv?dl=1).\n",
    "\n",
    "A couple notes about this lab:\n",
    "\n",
    "1.  Although it isn't listed as a specific question, don't forget to clean your data at the beginning. How will you handle missing data? Are there any variables that need adjusting?\n",
    "\n",
    "2.  There are a **lot** of variables in the dataset! You may want to use the `remainder = \"passthrough\"` trick in your column transformers, rather than typing out a ton of gene names.\n",
    "\n",
    "3.  Don't forget that in penalized regression, we **must** standardize our numeric variables.\n",
    "\n",
    "4.  There is a lot of repetition in this lab. Think about ways to streamline your code - for example, you might consider writing simple functions to easily create pipelines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "4381c603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "hitters = pd.read_csv(\"Hitters.csv\")\n",
    "\n",
    "# Remove rows with no value for salary \n",
    "hitters = hitters.dropna(subset=[\"Salary\"])\n",
    "hitters = hitters.reset_index(drop=True)\n",
    "\n",
    "# Assign values\n",
    "X = hitters.drop(columns=[\"Salary\"])\n",
    "y = hitters[\"Salary\"]\n",
    "\n",
    "# Train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=67)\n",
    "\n",
    "# Model Library \n",
    "model_library = {}\n",
    "records = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "c104deb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AtBat</th>\n",
       "      <th>Hits</th>\n",
       "      <th>HmRun</th>\n",
       "      <th>Runs</th>\n",
       "      <th>RBI</th>\n",
       "      <th>Walks</th>\n",
       "      <th>Years</th>\n",
       "      <th>CAtBat</th>\n",
       "      <th>CHits</th>\n",
       "      <th>CHmRun</th>\n",
       "      <th>CRuns</th>\n",
       "      <th>CRBI</th>\n",
       "      <th>CWalks</th>\n",
       "      <th>League</th>\n",
       "      <th>Division</th>\n",
       "      <th>PutOuts</th>\n",
       "      <th>Assists</th>\n",
       "      <th>Errors</th>\n",
       "      <th>Salary</th>\n",
       "      <th>NewLeague</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>315</td>\n",
       "      <td>81</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>3449</td>\n",
       "      <td>835</td>\n",
       "      <td>69</td>\n",
       "      <td>321</td>\n",
       "      <td>414</td>\n",
       "      <td>375</td>\n",
       "      <td>N</td>\n",
       "      <td>W</td>\n",
       "      <td>632</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>475.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>479</td>\n",
       "      <td>130</td>\n",
       "      <td>18</td>\n",
       "      <td>66</td>\n",
       "      <td>72</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "      <td>1624</td>\n",
       "      <td>457</td>\n",
       "      <td>63</td>\n",
       "      <td>224</td>\n",
       "      <td>266</td>\n",
       "      <td>263</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>880</td>\n",
       "      <td>82</td>\n",
       "      <td>14</td>\n",
       "      <td>480.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>496</td>\n",
       "      <td>141</td>\n",
       "      <td>20</td>\n",
       "      <td>65</td>\n",
       "      <td>78</td>\n",
       "      <td>37</td>\n",
       "      <td>11</td>\n",
       "      <td>5628</td>\n",
       "      <td>1575</td>\n",
       "      <td>225</td>\n",
       "      <td>828</td>\n",
       "      <td>838</td>\n",
       "      <td>354</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>200</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>500.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>321</td>\n",
       "      <td>87</td>\n",
       "      <td>10</td>\n",
       "      <td>39</td>\n",
       "      <td>42</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>396</td>\n",
       "      <td>101</td>\n",
       "      <td>12</td>\n",
       "      <td>48</td>\n",
       "      <td>46</td>\n",
       "      <td>33</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>805</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>91.5</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>594</td>\n",
       "      <td>169</td>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>51</td>\n",
       "      <td>35</td>\n",
       "      <td>11</td>\n",
       "      <td>4408</td>\n",
       "      <td>1133</td>\n",
       "      <td>19</td>\n",
       "      <td>501</td>\n",
       "      <td>336</td>\n",
       "      <td>194</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>282</td>\n",
       "      <td>421</td>\n",
       "      <td>25</td>\n",
       "      <td>750.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AtBat  Hits  HmRun  Runs  RBI  Walks  Years  CAtBat  CHits  CHmRun  CRuns  CRBI  CWalks League Division  PutOuts  Assists  Errors  Salary NewLeague\n",
       "0    315    81      7    24   38     39     14    3449    835      69    321   414     375      N        W      632       43      10   475.0         N\n",
       "1    479   130     18    66   72     76      3    1624    457      63    224   266     263      A        W      880       82      14   480.0         A\n",
       "2    496   141     20    65   78     37     11    5628   1575     225    828   838     354      N        E      200       11       3   500.0         N\n",
       "3    321    87     10    39   42     30      2     396    101      12     48    46      33      N        E      805       40       4    91.5         N\n",
       "4    594   169      4    74   51     35     11    4408   1133      19    501   336     194      A        W      282      421      25   750.0         A"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hitters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "db2a98ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column Transformer \n",
    "ct = ColumnTransformer(\n",
    "    [\n",
    "        (\"standardize\", \n",
    "         StandardScaler(), \n",
    "         make_column_selector(dtype_include=np.number)),\n",
    "        (\"cat\", \n",
    "         OneHotEncoder(drop=\"first\", sparse_output=False), \n",
    "         make_column_selector(dtype_include=object))\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    "    verbose_feature_names_out=False,\n",
    ").set_output(transform=\"pandas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c448b81",
   "metadata": {},
   "source": [
    "# Part I: Different Model Specs\n",
    "\n",
    "## A. Regression without regularization\n",
    "\n",
    "1.  Create a pipeline that includes *all* the columns as predictors for `Salary`, and performs ordinary linear regression\n",
    "\n",
    "2.  Fit this pipeline to the full dataset, and interpret a few of the most important coefficients.\n",
    "\n",
    "3.  Use cross-validation to estimate the MSE you would expect if you used this pipeline to predict 1989 salaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "303db950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Model Name\n",
    "# model_name = \"All_Features\"\n",
    "# regression_type = \"Linear\"  \n",
    "\n",
    "# # Cross Validation Pipeline\n",
    "# pipe = Pipeline([\n",
    "#     (\"preprocess\", ct),\n",
    "#     (\"linear_regression\", LinearRegression())\n",
    "# ])\n",
    "\n",
    "# # Add to Library\n",
    "# model_library[model_name] = pipe.fit(X, y)\n",
    "\n",
    "# # Metrics Calculation \n",
    "# rmse = cross_val_score(pipe, X, y, cv=5, scoring='neg_root_mean_squared_error')\n",
    "# mse = cross_val_score(pipe, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "# r2 = cross_val_score(pipe, X, y, cv=5, scoring='r2')\n",
    "\n",
    "# # Metrics Storage \n",
    "# records.append({\n",
    "#     \"Model\": model_name,\n",
    "#     \"Regression Type\": regression_type,\n",
    "#     \"Best Alpha\": \"NA\", \n",
    "#     \"Best L1 Ratio\": \"NA\", \n",
    "#     \"Split\": \"CV-5\",\n",
    "#     \"RMSE Mean\": -rmse.mean(),\n",
    "#     \"MSE Mean\": -mse.mean(),\n",
    "#     \"R2 Mean\": r2.mean()\n",
    "# })\n",
    "\n",
    "# # Display\n",
    "# cumulative_models = (pd.DataFrame(records))\n",
    "# cumulative_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "d3249008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_linear_regression(model_name, features=None):\n",
    "    \"\"\"\n",
    "    model_name - will be stored in model_library\n",
    "    features - list or None\n",
    "    Returns: DataFrame \n",
    "    \"\"\"\n",
    "    regression_type = \"Linear\"\n",
    "    \n",
    "    # Select features\n",
    "    if features is not None:\n",
    "        X_subset = X[features]\n",
    "    else:\n",
    "        X_subset = X\n",
    "    \n",
    "    # Cross Validation Pipeline\n",
    "    pipe = Pipeline([\n",
    "        (\"preprocess\", ct),\n",
    "        (\"linear_regression\", LinearRegression())\n",
    "    ])\n",
    "    \n",
    "    # Fit and add to Library\n",
    "    pipe.fit(X_subset, y)\n",
    "    model_library[model_name] = pipe\n",
    "    \n",
    "    # Get top 10 coefficients\n",
    "    feature_names = pipe.named_steps['preprocess'].get_feature_names_out()\n",
    "    coefficients = pipe.named_steps['linear_regression'].coef_\n",
    "    \n",
    "    coef_df = pd.DataFrame({\n",
    "        'Variable': feature_names,\n",
    "        'Coefficient': coefficients\n",
    "    }).sort_values('Coefficient', key=abs, ascending=False).head(10)\n",
    "    \n",
    "    # Metrics Calculation \n",
    "    rmse = cross_val_score(pipe, X_subset, y, cv=5, scoring='neg_root_mean_squared_error')\n",
    "    mse = cross_val_score(pipe, X_subset, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    r2 = cross_val_score(pipe, X_subset, y, cv=5, scoring='r2')\n",
    "    \n",
    "    # Metrics Storage \n",
    "    records.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Regression Type\": regression_type,\n",
    "        \"Best Alpha\": \"NA\", \n",
    "        \"Best L1 Ratio\": \"NA\",\n",
    "        \"Variables Used\": len(X_subset.columns) if features else \"All\",\n",
    "        \"Top 10 Variables\": \", \".join(coef_df['Variable'].head(10).tolist()),\n",
    "        \"Top 10 Coefficients\": \", \".join([f\"{c:.2f}\" for c in coef_df['Coefficient'].head(10).tolist()]),\n",
    "        \"Split\": \"CV-5\",\n",
    "        \"RMSE Mean\": -rmse.mean(),\n",
    "        \"MSE Mean\": -mse.mean(),\n",
    "        \"R2 Mean\": r2.mean()\n",
    "    })\n",
    "    \n",
    "    # Display\n",
    "    cumulative_models = pd.DataFrame(records)\n",
    "    return cumulative_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "87f14b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Regression Type</th>\n",
       "      <th>Best Alpha</th>\n",
       "      <th>Best L1 Ratio</th>\n",
       "      <th>Variables Used</th>\n",
       "      <th>Top 10 Variables</th>\n",
       "      <th>Top 10 Coefficients</th>\n",
       "      <th>Split</th>\n",
       "      <th>RMSE Mean</th>\n",
       "      <th>MSE Mean</th>\n",
       "      <th>R2 Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All_Features_Linear</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>All</td>\n",
       "      <td>CRuns, CAtBat, Hits, AtBat, CRBI, CWalks, Walk...</td>\n",
       "      <td>480.75, -391.04, 337.83, -291.09, 260.69, -213...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>342.139591</td>\n",
       "      <td>121136.310318</td>\n",
       "      <td>0.343495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model Regression Type Best Alpha Best L1 Ratio  ... Split   RMSE Mean       MSE Mean   R2 Mean\n",
       "0  All_Features_Linear          Linear         NA            NA  ...  CV-5  342.139591  121136.310318  0.343495\n",
       "\n",
       "[1 rows x 11 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_linear_regression(\"All_Features_Linear\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665ad387",
   "metadata": {},
   "source": [
    "Interpretation: The top Coefficients for salary: CRuns (Career Runs), CAtBat (Career At-Bats), Hits (1986 Hits), etc. are what you would expec: more time playing = more mony. However some coefficients are negative, likely due to multicollinearity as a person who has more bats will have more hits who will have more runs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c23c6a",
   "metadata": {},
   "source": [
    "## B. Ridge regression\n",
    "\n",
    "1.  Create a pipeline that includes *all* the columns as predictors for `Salary`, and performs ordinary ridge regression\n",
    "\n",
    "2.  Use cross-validation to **tune** the $\\lambda$ hyperparameter.\n",
    "\n",
    "3.  Fit the pipeline with your chosen $\\lambda$ to the full dataset, and interpret a few of the most important coefficients.\n",
    "\n",
    "4.  Report the MSE you would expect if you used this pipeline to predict 1989 salaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "5a4db9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ridge_regression(model_name, features=None):\n",
    "    \"\"\"\n",
    "    model_name - will be stored in model_library\n",
    "    features - list or None\n",
    "    Returns: DataFrame \n",
    "    \"\"\"\n",
    "    regression_type = \"Ridge\"\n",
    "    \n",
    "    # Select features\n",
    "    if features is not None:\n",
    "        X_subset = X[features]\n",
    "    else:\n",
    "        X_subset = X\n",
    "    \n",
    "    # Pipeline with Ridge\n",
    "    pipe = Pipeline([\n",
    "        (\"preprocess\", ct),\n",
    "        (\"ridge\", Ridge())\n",
    "    ])\n",
    "    \n",
    "    # GridSearchCV \n",
    "    param_grid = {'ridge__alpha': np.logspace(-1, 2, 50)}\n",
    "    gscv = GridSearchCV(pipe, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "    gscv.fit(X_subset, y)\n",
    "    \n",
    "    # Add best model to Library\n",
    "    model_library[model_name] = gscv.best_estimator_\n",
    "    \n",
    "    # Get best alpha\n",
    "    best_alpha = gscv.best_params_['ridge__alpha']\n",
    "    \n",
    "    # Get top 10 coefficients\n",
    "    coef_df = pd.DataFrame({\n",
    "        'Variable': gscv.best_estimator_.named_steps['preprocess'].get_feature_names_out(),\n",
    "        'Coefficient': gscv.best_estimator_.named_steps['ridge'].coef_\n",
    "    }).sort_values('Coefficient', key=abs, ascending=False).head(10)\n",
    "    \n",
    "    # Store coefficients in model library\n",
    "    model_library[f\"{model_name}_coefficients\"] = coef_df\n",
    "    \n",
    "    # Metrics Calculation using best model\n",
    "    rmse = cross_val_score(gscv.best_estimator_, X_subset, y, cv=5, scoring='neg_root_mean_squared_error')\n",
    "    mse = cross_val_score(gscv.best_estimator_, X_subset, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    r2 = cross_val_score(gscv.best_estimator_, X_subset, y, cv=5, scoring='r2')\n",
    "    \n",
    "    # Metrics Storage \n",
    "    records.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Regression Type\": regression_type,\n",
    "        \"Best Alpha\": best_alpha, \n",
    "        \"Best L1 Ratio\": \"NA\",\n",
    "        \"Variables Used\": len(X_subset.columns) if features else \"All\",\n",
    "        \"Top 10 Variables\": \", \".join(coef_df['Variable'].head(10).tolist()),\n",
    "        \"Top 10 Coefficients\": \", \".join([f\"{c:.2f}\" for c in coef_df['Coefficient'].head(10).tolist()]),\n",
    "        \"Split\": \"CV-5\",\n",
    "        \"RMSE Mean\": -rmse.mean(),\n",
    "        \"MSE Mean\": -mse.mean(),\n",
    "        \"R2 Mean\": r2.mean()\n",
    "    })\n",
    "    \n",
    "    # Display\n",
    "    cumulative_models = pd.DataFrame(records)\n",
    "    return cumulative_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "bdab596f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Regression Type</th>\n",
       "      <th>Best Alpha</th>\n",
       "      <th>Best L1 Ratio</th>\n",
       "      <th>Variables Used</th>\n",
       "      <th>Top 10 Variables</th>\n",
       "      <th>Top 10 Coefficients</th>\n",
       "      <th>Split</th>\n",
       "      <th>RMSE Mean</th>\n",
       "      <th>MSE Mean</th>\n",
       "      <th>R2 Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All_Features_Linear</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>All</td>\n",
       "      <td>CRuns, CAtBat, Hits, AtBat, CRBI, CWalks, Walk...</td>\n",
       "      <td>480.75, -391.04, 337.83, -291.09, 260.69, -213...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>342.139591</td>\n",
       "      <td>121136.310318</td>\n",
       "      <td>0.343495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge_All_Tuned</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>3.393222</td>\n",
       "      <td>NA</td>\n",
       "      <td>All</td>\n",
       "      <td>Hits, AtBat, CRuns, CWalks, CHits, Division_W,...</td>\n",
       "      <td>233.42, -218.94, 203.43, -146.12, 119.93, -118...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>338.640502</td>\n",
       "      <td>118715.693998</td>\n",
       "      <td>0.363510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model Regression Type Best Alpha Best L1 Ratio  ... Split   RMSE Mean       MSE Mean   R2 Mean\n",
       "0  All_Features_Linear          Linear         NA            NA  ...  CV-5  342.139591  121136.310318  0.343495\n",
       "1      Ridge_All_Tuned           Ridge   3.393222            NA  ...  CV-5  338.640502  118715.693998  0.363510\n",
       "\n",
       "[2 rows x 11 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_ridge_regression(\"Ridge_All_Tuned\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d4dae8",
   "metadata": {},
   "source": [
    "Interpretation: The coefficients for ridge regression were very similar to normal linear but in a different order and the coefficient number are smaller.. There is still an issue with multicollinearity "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e8660f",
   "metadata": {},
   "source": [
    "## C. Lasso Regression\n",
    "\n",
    "1.  Create a pipeline that includes *all* the columns as predictors for `Salary`, and performs ordinary ridge regression\n",
    "\n",
    "2.  Use cross-validation to **tune** the $\\lambda$ hyperparameter.\n",
    "\n",
    "3.  Fit the pipeline with your chosen $\\lambda$ to the full dataset, and interpret a few of the most important coefficients.\n",
    "\n",
    "4.  Report the MSE you would expect if you used this pipeline to predict 1989 salaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "4e05e7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lasso_regression(model_name, features=None):\n",
    "    \"\"\"\n",
    "    model_name - will be stored in model_library\n",
    "    features - list or None\n",
    "    Returns: DataFrame \n",
    "    \"\"\"\n",
    "    regression_type = \"Lasso\"\n",
    "    \n",
    "    # Select features\n",
    "    if features is not None:\n",
    "        X_subset = X[features]\n",
    "    else:\n",
    "        X_subset = X\n",
    "    \n",
    "    # Pipeline with Lasso\n",
    "    pipe = Pipeline([\n",
    "        (\"preprocess\", ct),\n",
    "        (\"lasso\", Lasso())\n",
    "    ])\n",
    "    \n",
    "    # GridSearchCV to tune alpha\n",
    "    param_grid = {'lasso__alpha': np.logspace(-1, 2, 50)}\n",
    "    gscv = GridSearchCV(pipe, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "    gscv.fit(X_subset, y)\n",
    "    \n",
    "    # Add best model to Library\n",
    "    model_library[model_name] = gscv.best_estimator_\n",
    "    \n",
    "    # Get best alpha\n",
    "    best_alpha = gscv.best_params_['lasso__alpha']\n",
    "    \n",
    "    # Get top 10 coefficients\n",
    "    coef_df = pd.DataFrame({\n",
    "        'Variable': gscv.best_estimator_.named_steps['preprocess'].get_feature_names_out(),\n",
    "        'Coefficient': gscv.best_estimator_.named_steps['lasso'].coef_\n",
    "    }).sort_values('Coefficient', key=abs, ascending=False).head(10)\n",
    "    \n",
    "    # Store coefficients in model library\n",
    "    model_library[f\"{model_name}_coefficients\"] = coef_df\n",
    "    \n",
    "    # Metrics Calculation using best model\n",
    "    rmse = cross_val_score(gscv.best_estimator_, X_subset, y, cv=5, scoring='neg_root_mean_squared_error')\n",
    "    mse = cross_val_score(gscv.best_estimator_, X_subset, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    r2 = cross_val_score(gscv.best_estimator_, X_subset, y, cv=5, scoring='r2')\n",
    "    \n",
    "    # Metrics Storage \n",
    "    records.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Regression Type\": regression_type,\n",
    "        \"Best Alpha\": best_alpha, \n",
    "        \"Best L1 Ratio\": \"NA\",\n",
    "        \"Variables Used\": len(X_subset.columns) if features else \"All\",\n",
    "        \"Top 10 Variables\": \", \".join(coef_df['Variable'].head(10).tolist()),\n",
    "        \"Top 10 Coefficients\": \", \".join([f\"{c:.2f}\" for c in coef_df['Coefficient'].head(10).tolist()]),\n",
    "        \"Split\": \"CV-5\",\n",
    "        \"RMSE Mean\": -rmse.mean(),\n",
    "        \"MSE Mean\": -mse.mean(),\n",
    "        \"R2 Mean\": r2.mean()\n",
    "    })\n",
    "    \n",
    "    # Display\n",
    "    cumulative_models = pd.DataFrame(records)\n",
    "    return cumulative_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "6627c87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.977e+04, tolerance: 4.708e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.719e+05, tolerance: 3.606e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.154e+05, tolerance: 4.137e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.956e+04, tolerance: 4.281e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.296e+05, tolerance: 4.558e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.296e+04, tolerance: 4.708e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.585e+05, tolerance: 3.606e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.709e+05, tolerance: 4.137e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.405e+04, tolerance: 4.281e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.629e+05, tolerance: 4.558e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.976e+04, tolerance: 4.708e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.087e+04, tolerance: 3.606e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.355e+05, tolerance: 4.137e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.926e+04, tolerance: 4.281e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.188e+04, tolerance: 4.558e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.978e+04, tolerance: 4.708e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.305e+04, tolerance: 3.606e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.078e+05, tolerance: 4.137e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.558e+04, tolerance: 4.281e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.280e+04, tolerance: 4.558e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.229e+04, tolerance: 4.708e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.280e+03, tolerance: 3.606e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.573e+04, tolerance: 4.137e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.218e+04, tolerance: 4.281e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.836e+04, tolerance: 4.558e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.671e+04, tolerance: 4.708e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.460e+04, tolerance: 4.137e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.306e+03, tolerance: 4.281e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.521e+04, tolerance: 4.558e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.252e+04, tolerance: 4.708e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.705e+04, tolerance: 4.137e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.983e+03, tolerance: 4.281e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.187e+03, tolerance: 4.558e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.520e+03, tolerance: 4.708e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.781e+04, tolerance: 3.606e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.485e+05, tolerance: 4.137e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.013e+03, tolerance: 4.281e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.796e+03, tolerance: 4.708e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.384e+05, tolerance: 4.137e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.473e+03, tolerance: 4.708e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.357e+05, tolerance: 4.137e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.432e+03, tolerance: 4.708e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.684e+05, tolerance: 4.137e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.603e+04, tolerance: 4.137e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.610e+04, tolerance: 4.137e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.367e+04, tolerance: 4.137e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.543e+03, tolerance: 4.137e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.293e+03, tolerance: 4.281e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.700e+03, tolerance: 4.281e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.772e+03, tolerance: 4.281e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.592e+03, tolerance: 4.281e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.812e+03, tolerance: 4.281e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.357e+03, tolerance: 4.281e+03\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Regression Type</th>\n",
       "      <th>Best Alpha</th>\n",
       "      <th>Best L1 Ratio</th>\n",
       "      <th>Variables Used</th>\n",
       "      <th>Top 10 Variables</th>\n",
       "      <th>Top 10 Coefficients</th>\n",
       "      <th>Split</th>\n",
       "      <th>RMSE Mean</th>\n",
       "      <th>MSE Mean</th>\n",
       "      <th>R2 Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All_Features_Linear</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>All</td>\n",
       "      <td>CRuns, CAtBat, Hits, AtBat, CRBI, CWalks, Walk...</td>\n",
       "      <td>480.75, -391.04, 337.83, -291.09, 260.69, -213...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>342.139591</td>\n",
       "      <td>121136.310318</td>\n",
       "      <td>0.343495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge_All_Tuned</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>3.393222</td>\n",
       "      <td>NA</td>\n",
       "      <td>All</td>\n",
       "      <td>Hits, AtBat, CRuns, CWalks, CHits, Division_W,...</td>\n",
       "      <td>233.42, -218.94, 203.43, -146.12, 119.93, -118...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>338.640502</td>\n",
       "      <td>118715.693998</td>\n",
       "      <td>0.363510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso_All_Tuned</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>2.222996</td>\n",
       "      <td>NA</td>\n",
       "      <td>All</td>\n",
       "      <td>Hits, AtBat, CRuns, CWalks, CRBI, Division_W, ...</td>\n",
       "      <td>269.91, -249.36, 233.40, -153.72, 122.59, -114...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>339.164091</td>\n",
       "      <td>119077.752512</td>\n",
       "      <td>0.364623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model Regression Type Best Alpha Best L1 Ratio  ... Split   RMSE Mean       MSE Mean   R2 Mean\n",
       "0  All_Features_Linear          Linear         NA            NA  ...  CV-5  342.139591  121136.310318  0.343495\n",
       "1      Ridge_All_Tuned           Ridge   3.393222            NA  ...  CV-5  338.640502  118715.693998  0.363510\n",
       "2      Lasso_All_Tuned           Lasso   2.222996            NA  ...  CV-5  339.164091  119077.752512  0.364623\n",
       "\n",
       "[3 rows x 11 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_lasso_regression(\"Lasso_All_Tuned\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696a7f74",
   "metadata": {},
   "source": [
    "## D. Elastic Net\n",
    "\n",
    "1.  Create a pipeline that includes *all* the columns as predictors for `Salary`, and performs ordinary ridge regression\n",
    "\n",
    "2.  Use cross-validation to **tune** the $\\lambda$ and $\\alpha$ hyperparameters.\n",
    "\n",
    "3.  Fit the pipeline with your chosen hyperparameters to the full dataset, and interpret a few of the most important coefficients.\n",
    "\n",
    "4.  Report the MSE you would expect if you used this pipeline to predict 1989 salaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "0fd31274",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_elasticnet_regression(model_name, features=None):\n",
    "    \"\"\"\n",
    "    model_name - will be stored in model_library\n",
    "    features - list or None\n",
    "    Returns: DataFrame \n",
    "    \"\"\"\n",
    "    regression_type = \"ElasticNet\"\n",
    "    \n",
    "    # Select features\n",
    "    if features is not None:\n",
    "        X_subset = X[features]\n",
    "    else:\n",
    "        X_subset = X\n",
    "    \n",
    "    # Pipeline with ElasticNet\n",
    "    pipe = Pipeline([\n",
    "        (\"preprocess\", ct),\n",
    "        (\"elasticnet\", ElasticNet())\n",
    "    ])\n",
    "    \n",
    "    # GridSearchCV to tune alpha and l1_ratio\n",
    "    param_grid = {\n",
    "        'elasticnet__alpha': np.logspace(-1, 2, 50),\n",
    "        'elasticnet__l1_ratio': [0, 0.25, 0.5, 0.75, 1]\n",
    "    }\n",
    "    gscv = GridSearchCV(pipe, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "    gscv.fit(X_subset, y)\n",
    "    \n",
    "    # Add best model to Library\n",
    "    model_library[model_name] = gscv.best_estimator_\n",
    "    \n",
    "    # Get best hyperparameters\n",
    "    best_alpha = gscv.best_params_['elasticnet__alpha']\n",
    "    best_l1_ratio = gscv.best_params_['elasticnet__l1_ratio']\n",
    "    \n",
    "    # Get top 10 coefficients\n",
    "    coef_df = pd.DataFrame({\n",
    "        'Variable': gscv.best_estimator_.named_steps['preprocess'].get_feature_names_out(),\n",
    "        'Coefficient': gscv.best_estimator_.named_steps['elasticnet'].coef_\n",
    "    }).sort_values('Coefficient', key=abs, ascending=False).head(10)\n",
    "    \n",
    "    # Store coefficients in model library\n",
    "    model_library[f\"{model_name}_coefficients\"] = coef_df\n",
    "    \n",
    "    # Metrics Calculation using best model\n",
    "    rmse = cross_val_score(gscv.best_estimator_, X_subset, y, cv=5, scoring='neg_root_mean_squared_error')\n",
    "    mse = cross_val_score(gscv.best_estimator_, X_subset, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    r2 = cross_val_score(gscv.best_estimator_, X_subset, y, cv=5, scoring='r2')\n",
    "    \n",
    "    # Metrics Storage \n",
    "    records.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Regression Type\": regression_type,\n",
    "        \"Best Alpha\": best_alpha, \n",
    "        \"Best L1 Ratio\": best_l1_ratio,\n",
    "        \"Variables Used\": len(X_subset.columns) if features else \"All\",\n",
    "        \"Top 10 Variables\": \", \".join(coef_df['Variable'].head(10).tolist()),\n",
    "        \"Top 10 Coefficients\": \", \".join([f\"{c:.2f}\" for c in coef_df['Coefficient'].head(10).tolist()]),\n",
    "        \"Split\": \"CV-5\",\n",
    "        \"RMSE Mean\": -rmse.mean(),\n",
    "        \"MSE Mean\": -mse.mean(),\n",
    "        \"R2 Mean\": r2.mean()\n",
    "    })\n",
    "    \n",
    "    # Display\n",
    "    cumulative_models = pd.DataFrame(records)\n",
    "    return cumulative_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "c6a0dfc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.225e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.010e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.183e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.083e+06, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.145e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.977e+04, tolerance: 4.708e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.719e+05, tolerance: 3.606e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.154e+05, tolerance: 4.137e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.956e+04, tolerance: 4.281e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.296e+05, tolerance: 4.558e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.236e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.016e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.191e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.176e+06, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.154e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.296e+04, tolerance: 4.708e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.585e+05, tolerance: 3.606e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.709e+05, tolerance: 4.137e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.405e+04, tolerance: 4.281e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.629e+05, tolerance: 4.558e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.248e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.021e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.198e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.272e+06, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.164e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.976e+04, tolerance: 4.708e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.087e+04, tolerance: 3.606e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.355e+05, tolerance: 4.137e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.926e+04, tolerance: 4.281e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.188e+04, tolerance: 4.558e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.261e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.027e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.206e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.372e+06, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.174e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.978e+04, tolerance: 4.708e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.305e+04, tolerance: 3.606e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.078e+05, tolerance: 4.137e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.558e+04, tolerance: 4.281e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.280e+04, tolerance: 4.558e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.273e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.033e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.214e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.474e+06, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.185e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.229e+04, tolerance: 4.708e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.280e+03, tolerance: 3.606e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.573e+04, tolerance: 4.137e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.218e+04, tolerance: 4.281e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.836e+04, tolerance: 4.558e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.286e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.040e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.222e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.581e+06, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.196e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.671e+04, tolerance: 4.708e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.460e+04, tolerance: 4.137e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.306e+03, tolerance: 4.281e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.521e+04, tolerance: 4.558e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.299e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.047e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.230e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.692e+06, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.207e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.252e+04, tolerance: 4.708e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.705e+04, tolerance: 4.137e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.983e+03, tolerance: 4.281e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.187e+03, tolerance: 4.558e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.313e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.055e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.238e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.807e+06, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.219e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.520e+03, tolerance: 4.708e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.781e+04, tolerance: 3.606e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.485e+05, tolerance: 4.137e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.013e+03, tolerance: 4.281e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.327e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.062e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.247e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.928e+06, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.232e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.796e+03, tolerance: 4.708e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.384e+05, tolerance: 4.137e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.342e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.071e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.256e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.006e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.245e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.473e+03, tolerance: 4.708e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.357e+05, tolerance: 4.137e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.357e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.080e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.266e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.019e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.259e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.432e+03, tolerance: 4.708e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.684e+05, tolerance: 4.137e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.373e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.089e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.276e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.033e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.273e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.603e+04, tolerance: 4.137e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.389e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.100e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.287e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.048e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.288e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.610e+04, tolerance: 4.137e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.406e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.111e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.299e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.064e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.304e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.367e+04, tolerance: 4.137e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.424e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.122e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.311e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.082e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.321e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.543e+03, tolerance: 4.137e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.443e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.135e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.324e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.100e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.339e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.463e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.149e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.338e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.120e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.358e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.293e+03, tolerance: 4.281e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.485e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.163e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.353e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.141e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.378e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.700e+03, tolerance: 4.281e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.507e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.179e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.370e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.164e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.400e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.772e+03, tolerance: 4.281e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.531e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.195e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.387e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.188e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.423e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.592e+03, tolerance: 4.281e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.556e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.213e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.406e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.214e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.448e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.812e+03, tolerance: 4.281e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.583e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.232e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.426e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.242e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.473e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.357e+03, tolerance: 4.281e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.611e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.251e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.448e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.272e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.501e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.640e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.272e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.470e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.304e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.530e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.670e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.295e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.494e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.337e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.560e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.702e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.318e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.519e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.372e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.592e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.735e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.342e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.546e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.408e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.625e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.769e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.366e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.573e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.446e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.659e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.803e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.391e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.601e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.485e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.694e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.838e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.417e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.629e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.524e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.729e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.873e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.443e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.658e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.564e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.765e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.908e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.468e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.686e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.604e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.801e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.942e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.493e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.715e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.643e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.836e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.975e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.518e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.742e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.682e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.871e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.007e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.542e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.770e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.720e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.904e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.038e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.565e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.796e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.756e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.937e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.067e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.587e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.820e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.791e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.968e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.095e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.608e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.844e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.824e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.997e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.121e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.627e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.866e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.855e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.025e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.145e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.645e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.887e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.884e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.051e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.167e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.662e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.906e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.911e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.075e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.187e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.677e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.923e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.935e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.097e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.206e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.691e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.939e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.958e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.117e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.223e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.704e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.954e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.978e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.135e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.238e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.715e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.967e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.997e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.151e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.251e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.725e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.979e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.014e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.166e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.264e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.735e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.990e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.029e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.180e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.275e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.743e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.999e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.042e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.192e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.284e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.750e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.008e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.054e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.202e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.293e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.757e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.015e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.065e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.212e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Regression Type</th>\n",
       "      <th>Best Alpha</th>\n",
       "      <th>Best L1 Ratio</th>\n",
       "      <th>Variables Used</th>\n",
       "      <th>Top 10 Variables</th>\n",
       "      <th>Top 10 Coefficients</th>\n",
       "      <th>Split</th>\n",
       "      <th>RMSE Mean</th>\n",
       "      <th>MSE Mean</th>\n",
       "      <th>R2 Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All_Features_Linear</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>All</td>\n",
       "      <td>CRuns, CAtBat, Hits, AtBat, CRBI, CWalks, Walk...</td>\n",
       "      <td>480.75, -391.04, 337.83, -291.09, 260.69, -213...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>342.139591</td>\n",
       "      <td>121136.310318</td>\n",
       "      <td>0.343495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge_All_Tuned</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>3.393222</td>\n",
       "      <td>NA</td>\n",
       "      <td>All</td>\n",
       "      <td>Hits, AtBat, CRuns, CWalks, CHits, Division_W,...</td>\n",
       "      <td>233.42, -218.94, 203.43, -146.12, 119.93, -118...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>338.640502</td>\n",
       "      <td>118715.693998</td>\n",
       "      <td>0.363510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso_All_Tuned</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>2.222996</td>\n",
       "      <td>NA</td>\n",
       "      <td>All</td>\n",
       "      <td>Hits, AtBat, CRuns, CWalks, CRBI, Division_W, ...</td>\n",
       "      <td>269.91, -249.36, 233.40, -153.72, 122.59, -114...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>339.164091</td>\n",
       "      <td>119077.752512</td>\n",
       "      <td>0.364623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ElasticNet_All_Tuned</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>All</td>\n",
       "      <td>Hits, AtBat, CRuns, Division_W, CWalks, CHits,...</td>\n",
       "      <td>183.90, -168.73, 147.09, -115.34, -114.21, 105...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>338.523418</td>\n",
       "      <td>118776.366833</td>\n",
       "      <td>0.366784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model Regression Type Best Alpha Best L1 Ratio  ... Split   RMSE Mean       MSE Mean   R2 Mean\n",
       "0   All_Features_Linear          Linear         NA            NA  ...  CV-5  342.139591  121136.310318  0.343495\n",
       "1       Ridge_All_Tuned           Ridge   3.393222            NA  ...  CV-5  338.640502  118715.693998  0.363510\n",
       "2       Lasso_All_Tuned           Lasso   2.222996            NA  ...  CV-5  339.164091  119077.752512  0.364623\n",
       "3  ElasticNet_All_Tuned      ElasticNet        0.1          0.75  ...  CV-5  338.523418  118776.366833  0.366784\n",
       "\n",
       "[4 rows x 11 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_elasticnet_regression(\"ElasticNet_All_Tuned\",None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cc1179",
   "metadata": {},
   "source": [
    "# Part II. Variable Selection\n",
    "\n",
    "Based on the above results, decide on:\n",
    "\n",
    "-   Which *numeric* variable is most important: \n",
    "\n",
    "        Hits\n",
    "\n",
    "-   Which *five* numeric variables are most important:\n",
    "\n",
    "        1. CRuns\n",
    "        2. Hits\n",
    "        3. AtBat\n",
    "        4. CRBI\n",
    "        5. CWalks\n",
    "\n",
    "-   Which *categorical* variable is most important: \n",
    "        \n",
    "        Division_W\n",
    "\n",
    "For **each** of the four model specifications, compare the following possible feature sets:\n",
    "\n",
    "Report which combination of features and model performed best, based on the validation metric of MSE.\n",
    "\n",
    "(Note: $\\lambda$ and $\\alpha$ must be re-tuned for each feature set.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c43373",
   "metadata": {},
   "source": [
    "## 1.  Using only the one best numeric variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "bb2f26c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Regression Type</th>\n",
       "      <th>Best Alpha</th>\n",
       "      <th>Best L1 Ratio</th>\n",
       "      <th>Variables Used</th>\n",
       "      <th>Top 10 Variables</th>\n",
       "      <th>Top 10 Coefficients</th>\n",
       "      <th>Split</th>\n",
       "      <th>RMSE Mean</th>\n",
       "      <th>MSE Mean</th>\n",
       "      <th>R2 Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All_Features_Linear</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>All</td>\n",
       "      <td>CRuns, CAtBat, Hits, AtBat, CRBI, CWalks, Walk...</td>\n",
       "      <td>480.75, -391.04, 337.83, -291.09, 260.69, -213...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>342.139591</td>\n",
       "      <td>121136.310318</td>\n",
       "      <td>0.343495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge_All_Tuned</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>3.393222</td>\n",
       "      <td>NA</td>\n",
       "      <td>All</td>\n",
       "      <td>Hits, AtBat, CRuns, CWalks, CHits, Division_W,...</td>\n",
       "      <td>233.42, -218.94, 203.43, -146.12, 119.93, -118...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>338.640502</td>\n",
       "      <td>118715.693998</td>\n",
       "      <td>0.363510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso_All_Tuned</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>2.222996</td>\n",
       "      <td>NA</td>\n",
       "      <td>All</td>\n",
       "      <td>Hits, AtBat, CRuns, CWalks, CRBI, Division_W, ...</td>\n",
       "      <td>269.91, -249.36, 233.40, -153.72, 122.59, -114...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>339.164091</td>\n",
       "      <td>119077.752512</td>\n",
       "      <td>0.364623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ElasticNet_All_Tuned</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>All</td>\n",
       "      <td>Hits, AtBat, CRuns, Division_W, CWalks, CHits,...</td>\n",
       "      <td>183.90, -168.73, 147.09, -115.34, -114.21, 105...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>338.523418</td>\n",
       "      <td>118776.366833</td>\n",
       "      <td>0.366784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hits_Linear</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>Hits</td>\n",
       "      <td>197.52</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>408.435433</td>\n",
       "      <td>173088.972864</td>\n",
       "      <td>0.122213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model Regression Type Best Alpha Best L1 Ratio  ... Split   RMSE Mean       MSE Mean   R2 Mean\n",
       "0   All_Features_Linear          Linear         NA            NA  ...  CV-5  342.139591  121136.310318  0.343495\n",
       "1       Ridge_All_Tuned           Ridge   3.393222            NA  ...  CV-5  338.640502  118715.693998  0.363510\n",
       "2       Lasso_All_Tuned           Lasso   2.222996            NA  ...  CV-5  339.164091  119077.752512  0.364623\n",
       "3  ElasticNet_All_Tuned      ElasticNet        0.1          0.75  ...  CV-5  338.523418  118776.366833  0.366784\n",
       "4           Hits_Linear          Linear         NA            NA  ...  CV-5  408.435433  173088.972864  0.122213\n",
       "\n",
       "[5 rows x 11 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_linear_regression(\"Hits_Linear\", features=['Hits'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "2f6e81be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Regression Type</th>\n",
       "      <th>Best Alpha</th>\n",
       "      <th>Best L1 Ratio</th>\n",
       "      <th>Variables Used</th>\n",
       "      <th>Top 10 Variables</th>\n",
       "      <th>Top 10 Coefficients</th>\n",
       "      <th>Split</th>\n",
       "      <th>RMSE Mean</th>\n",
       "      <th>MSE Mean</th>\n",
       "      <th>R2 Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All_Features_Linear</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>All</td>\n",
       "      <td>CRuns, CAtBat, Hits, AtBat, CRBI, CWalks, Walk...</td>\n",
       "      <td>480.75, -391.04, 337.83, -291.09, 260.69, -213...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>342.139591</td>\n",
       "      <td>121136.310318</td>\n",
       "      <td>0.343495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge_All_Tuned</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>3.393222</td>\n",
       "      <td>NA</td>\n",
       "      <td>All</td>\n",
       "      <td>Hits, AtBat, CRuns, CWalks, CHits, Division_W,...</td>\n",
       "      <td>233.42, -218.94, 203.43, -146.12, 119.93, -118...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>338.640502</td>\n",
       "      <td>118715.693998</td>\n",
       "      <td>0.363510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso_All_Tuned</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>2.222996</td>\n",
       "      <td>NA</td>\n",
       "      <td>All</td>\n",
       "      <td>Hits, AtBat, CRuns, CWalks, CRBI, Division_W, ...</td>\n",
       "      <td>269.91, -249.36, 233.40, -153.72, 122.59, -114...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>339.164091</td>\n",
       "      <td>119077.752512</td>\n",
       "      <td>0.364623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ElasticNet_All_Tuned</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>All</td>\n",
       "      <td>Hits, AtBat, CRuns, Division_W, CWalks, CHits,...</td>\n",
       "      <td>183.90, -168.73, 147.09, -115.34, -114.21, 105...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>338.523418</td>\n",
       "      <td>118776.366833</td>\n",
       "      <td>0.366784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hits_Linear</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>Hits</td>\n",
       "      <td>197.52</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>408.435433</td>\n",
       "      <td>173088.972864</td>\n",
       "      <td>0.122213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hits_Ridge</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>24.420531</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>Hits</td>\n",
       "      <td>180.74</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>407.841429</td>\n",
       "      <td>172580.243054</td>\n",
       "      <td>0.128410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model Regression Type Best Alpha Best L1 Ratio  ... Split   RMSE Mean       MSE Mean   R2 Mean\n",
       "0   All_Features_Linear          Linear         NA            NA  ...  CV-5  342.139591  121136.310318  0.343495\n",
       "1       Ridge_All_Tuned           Ridge   3.393222            NA  ...  CV-5  338.640502  118715.693998  0.363510\n",
       "2       Lasso_All_Tuned           Lasso   2.222996            NA  ...  CV-5  339.164091  119077.752512  0.364623\n",
       "3  ElasticNet_All_Tuned      ElasticNet        0.1          0.75  ...  CV-5  338.523418  118776.366833  0.366784\n",
       "4           Hits_Linear          Linear         NA            NA  ...  CV-5  408.435433  173088.972864  0.122213\n",
       "5            Hits_Ridge           Ridge  24.420531            NA  ...  CV-5  407.841429  172580.243054  0.128410\n",
       "\n",
       "[6 rows x 11 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_ridge_regression(\"Hits_Ridge\", features=['Hits'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "9621576f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Regression Type</th>\n",
       "      <th>Best Alpha</th>\n",
       "      <th>Best L1 Ratio</th>\n",
       "      <th>Variables Used</th>\n",
       "      <th>Top 10 Variables</th>\n",
       "      <th>Top 10 Coefficients</th>\n",
       "      <th>Split</th>\n",
       "      <th>RMSE Mean</th>\n",
       "      <th>MSE Mean</th>\n",
       "      <th>R2 Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All_Features_Linear</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>All</td>\n",
       "      <td>CRuns, CAtBat, Hits, AtBat, CRBI, CWalks, Walk...</td>\n",
       "      <td>480.75, -391.04, 337.83, -291.09, 260.69, -213...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>342.139591</td>\n",
       "      <td>121136.310318</td>\n",
       "      <td>0.343495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge_All_Tuned</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>3.393222</td>\n",
       "      <td>NA</td>\n",
       "      <td>All</td>\n",
       "      <td>Hits, AtBat, CRuns, CWalks, CHits, Division_W,...</td>\n",
       "      <td>233.42, -218.94, 203.43, -146.12, 119.93, -118...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>338.640502</td>\n",
       "      <td>118715.693998</td>\n",
       "      <td>0.363510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso_All_Tuned</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>2.222996</td>\n",
       "      <td>NA</td>\n",
       "      <td>All</td>\n",
       "      <td>Hits, AtBat, CRuns, CWalks, CRBI, Division_W, ...</td>\n",
       "      <td>269.91, -249.36, 233.40, -153.72, 122.59, -114...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>339.164091</td>\n",
       "      <td>119077.752512</td>\n",
       "      <td>0.364623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ElasticNet_All_Tuned</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>All</td>\n",
       "      <td>Hits, AtBat, CRuns, Division_W, CWalks, CHits,...</td>\n",
       "      <td>183.90, -168.73, 147.09, -115.34, -114.21, 105...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>338.523418</td>\n",
       "      <td>118776.366833</td>\n",
       "      <td>0.366784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hits_Linear</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>Hits</td>\n",
       "      <td>197.52</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>408.435433</td>\n",
       "      <td>173088.972864</td>\n",
       "      <td>0.122213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hits_Ridge</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>24.420531</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>Hits</td>\n",
       "      <td>180.74</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>407.841429</td>\n",
       "      <td>172580.243054</td>\n",
       "      <td>0.128410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hits_Lasso</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>5.963623</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>Hits</td>\n",
       "      <td>191.55</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>408.373539</td>\n",
       "      <td>173047.782853</td>\n",
       "      <td>0.123640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model Regression Type Best Alpha Best L1 Ratio  ... Split   RMSE Mean       MSE Mean   R2 Mean\n",
       "0   All_Features_Linear          Linear         NA            NA  ...  CV-5  342.139591  121136.310318  0.343495\n",
       "1       Ridge_All_Tuned           Ridge   3.393222            NA  ...  CV-5  338.640502  118715.693998  0.363510\n",
       "2       Lasso_All_Tuned           Lasso   2.222996            NA  ...  CV-5  339.164091  119077.752512  0.364623\n",
       "3  ElasticNet_All_Tuned      ElasticNet        0.1          0.75  ...  CV-5  338.523418  118776.366833  0.366784\n",
       "4           Hits_Linear          Linear         NA            NA  ...  CV-5  408.435433  173088.972864  0.122213\n",
       "5            Hits_Ridge           Ridge  24.420531            NA  ...  CV-5  407.841429  172580.243054  0.128410\n",
       "6            Hits_Lasso           Lasso   5.963623            NA  ...  CV-5  408.373539  173047.782853  0.123640\n",
       "\n",
       "[7 rows x 11 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_lasso_regression(\"Hits_Lasso\", features=['Hits'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "3c0da633",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.009e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.569e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.708e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.666e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.796e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.013e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.573e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.713e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.673e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.802e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.019e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.576e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.719e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.680e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.810e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.024e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.580e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.725e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.688e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.818e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.031e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.584e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.731e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.697e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.827e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.038e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.589e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.739e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.707e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.837e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.046e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.595e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.747e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.717e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.848e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.054e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.756e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.729e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.860e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.064e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.607e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.766e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.742e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.873e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.074e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.776e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.756e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.084e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.621e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.787e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.770e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.096e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.628e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.799e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.786e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.918e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.108e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.636e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.812e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.802e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.935e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.120e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.645e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.825e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.820e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.133e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.654e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.838e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.837e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.970e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.146e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.662e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.852e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.855e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.159e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.672e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.866e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.874e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.173e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.681e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.880e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.892e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.186e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.690e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.894e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.910e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.044e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.199e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.698e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.907e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.928e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.063e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.212e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.707e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.921e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.946e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.081e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.224e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.715e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.933e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.963e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.098e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.236e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.723e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.946e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.979e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.114e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.247e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.731e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.957e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.994e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.130e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.258e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.738e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.968e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.008e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.144e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.267e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.745e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.978e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.022e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.158e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.276e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.751e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.988e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.034e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.171e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.285e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.756e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.997e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.046e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.182e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.292e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.761e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.005e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.056e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.193e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.299e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.766e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.012e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.066e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.203e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.306e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.770e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.018e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.074e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.212e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.311e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.774e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.024e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.082e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.219e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.316e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.778e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.029e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.089e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.321e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.781e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.034e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.095e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.325e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.783e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.038e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.101e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.328e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.786e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.042e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.106e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.243e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.331e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.788e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.045e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.110e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.334e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.790e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.048e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.114e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.252e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.337e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.792e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.051e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.117e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.339e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.793e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.053e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.120e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.341e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.794e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.055e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.123e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.261e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.342e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.795e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.057e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.125e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.263e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.344e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.796e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.058e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.127e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.265e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.345e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.797e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.060e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.129e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.346e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.798e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.061e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.130e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.269e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.347e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.799e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.062e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.132e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.270e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.348e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.063e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.133e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.349e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.064e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.134e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.349e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.800e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.064e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.135e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.273e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.350e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.801e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.065e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.136e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.274e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.213e+07, tolerance: 5.332e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.019e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.576e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.719e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.680e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.810e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.019e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.576e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.719e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.680e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.810e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.019e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.576e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.719e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.680e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.810e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Regression Type</th>\n",
       "      <th>Best Alpha</th>\n",
       "      <th>Best L1 Ratio</th>\n",
       "      <th>Variables Used</th>\n",
       "      <th>Top 10 Variables</th>\n",
       "      <th>Top 10 Coefficients</th>\n",
       "      <th>Split</th>\n",
       "      <th>RMSE Mean</th>\n",
       "      <th>MSE Mean</th>\n",
       "      <th>R2 Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All_Features_Linear</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>All</td>\n",
       "      <td>CRuns, CAtBat, Hits, AtBat, CRBI, CWalks, Walk...</td>\n",
       "      <td>480.75, -391.04, 337.83, -291.09, 260.69, -213...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>342.139591</td>\n",
       "      <td>121136.310318</td>\n",
       "      <td>0.343495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge_All_Tuned</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>3.393222</td>\n",
       "      <td>NA</td>\n",
       "      <td>All</td>\n",
       "      <td>Hits, AtBat, CRuns, CWalks, CHits, Division_W,...</td>\n",
       "      <td>233.42, -218.94, 203.43, -146.12, 119.93, -118...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>338.640502</td>\n",
       "      <td>118715.693998</td>\n",
       "      <td>0.363510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso_All_Tuned</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>2.222996</td>\n",
       "      <td>NA</td>\n",
       "      <td>All</td>\n",
       "      <td>Hits, AtBat, CRuns, CWalks, CRBI, Division_W, ...</td>\n",
       "      <td>269.91, -249.36, 233.40, -153.72, 122.59, -114...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>339.164091</td>\n",
       "      <td>119077.752512</td>\n",
       "      <td>0.364623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ElasticNet_All_Tuned</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>All</td>\n",
       "      <td>Hits, AtBat, CRuns, Division_W, CWalks, CHits,...</td>\n",
       "      <td>183.90, -168.73, 147.09, -115.34, -114.21, 105...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>338.523418</td>\n",
       "      <td>118776.366833</td>\n",
       "      <td>0.366784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hits_Linear</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>Hits</td>\n",
       "      <td>197.52</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>408.435433</td>\n",
       "      <td>173088.972864</td>\n",
       "      <td>0.122213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hits_Ridge</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>24.420531</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>Hits</td>\n",
       "      <td>180.74</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>407.841429</td>\n",
       "      <td>172580.243054</td>\n",
       "      <td>0.128410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hits_Lasso</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>5.963623</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>Hits</td>\n",
       "      <td>191.55</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>408.373539</td>\n",
       "      <td>173047.782853</td>\n",
       "      <td>0.123640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hits_Elasticnet</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.132571</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hits</td>\n",
       "      <td>174.40</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>407.830061</td>\n",
       "      <td>172569.673986</td>\n",
       "      <td>0.128863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model Regression Type Best Alpha Best L1 Ratio  ... Split   RMSE Mean       MSE Mean   R2 Mean\n",
       "0   All_Features_Linear          Linear         NA            NA  ...  CV-5  342.139591  121136.310318  0.343495\n",
       "1       Ridge_All_Tuned           Ridge   3.393222            NA  ...  CV-5  338.640502  118715.693998  0.363510\n",
       "2       Lasso_All_Tuned           Lasso   2.222996            NA  ...  CV-5  339.164091  119077.752512  0.364623\n",
       "3  ElasticNet_All_Tuned      ElasticNet        0.1          0.75  ...  CV-5  338.523418  118776.366833  0.366784\n",
       "4           Hits_Linear          Linear         NA            NA  ...  CV-5  408.435433  173088.972864  0.122213\n",
       "5            Hits_Ridge           Ridge  24.420531            NA  ...  CV-5  407.841429  172580.243054  0.128410\n",
       "6            Hits_Lasso           Lasso   5.963623            NA  ...  CV-5  408.373539  173047.782853  0.123640\n",
       "7       Hits_Elasticnet      ElasticNet   0.132571             0  ...  CV-5  407.830061  172569.673986  0.128863\n",
       "\n",
       "[8 rows x 11 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_elasticnet_regression(\"Hits_Elasticnet\", features=['Hits'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6dd916",
   "metadata": {},
   "source": [
    "### Interpretation \n",
    "\n",
    "They were all roughly the same but Elastcicnet did the best in the MSE department "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55506c34",
   "metadata": {},
   "source": [
    "## 2.  Using only the five best variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "b3210f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Regression Type</th>\n",
       "      <th>Best Alpha</th>\n",
       "      <th>Best L1 Ratio</th>\n",
       "      <th>Variables Used</th>\n",
       "      <th>Top 10 Variables</th>\n",
       "      <th>Top 10 Coefficients</th>\n",
       "      <th>Split</th>\n",
       "      <th>RMSE Mean</th>\n",
       "      <th>MSE Mean</th>\n",
       "      <th>R2 Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All_Features_Linear</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>All</td>\n",
       "      <td>CRuns, CAtBat, Hits, AtBat, CRBI, CWalks, Walk...</td>\n",
       "      <td>480.75, -391.04, 337.83, -291.09, 260.69, -213...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>342.139591</td>\n",
       "      <td>121136.310318</td>\n",
       "      <td>0.343495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge_All_Tuned</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>3.393222</td>\n",
       "      <td>NA</td>\n",
       "      <td>All</td>\n",
       "      <td>Hits, AtBat, CRuns, CWalks, CHits, Division_W,...</td>\n",
       "      <td>233.42, -218.94, 203.43, -146.12, 119.93, -118...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>338.640502</td>\n",
       "      <td>118715.693998</td>\n",
       "      <td>0.363510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso_All_Tuned</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>2.222996</td>\n",
       "      <td>NA</td>\n",
       "      <td>All</td>\n",
       "      <td>Hits, AtBat, CRuns, CWalks, CRBI, Division_W, ...</td>\n",
       "      <td>269.91, -249.36, 233.40, -153.72, 122.59, -114...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>339.164091</td>\n",
       "      <td>119077.752512</td>\n",
       "      <td>0.364623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ElasticNet_All_Tuned</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>All</td>\n",
       "      <td>Hits, AtBat, CRuns, Division_W, CWalks, CHits,...</td>\n",
       "      <td>183.90, -168.73, 147.09, -115.34, -114.21, 105...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>338.523418</td>\n",
       "      <td>118776.366833</td>\n",
       "      <td>0.366784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hits_Linear</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>Hits</td>\n",
       "      <td>197.52</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>408.435433</td>\n",
       "      <td>173088.972864</td>\n",
       "      <td>0.122213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hits_Ridge</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>24.420531</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>Hits</td>\n",
       "      <td>180.74</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>407.841429</td>\n",
       "      <td>172580.243054</td>\n",
       "      <td>0.128410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hits_Lasso</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>5.963623</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>Hits</td>\n",
       "      <td>191.55</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>408.373539</td>\n",
       "      <td>173047.782853</td>\n",
       "      <td>0.123640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hits_Elasticnet</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.132571</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hits</td>\n",
       "      <td>174.40</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>407.830061</td>\n",
       "      <td>172569.673986</td>\n",
       "      <td>0.128863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Top5_Linear</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>5</td>\n",
       "      <td>Hits, AtBat, CRBI, CRuns, CWalks</td>\n",
       "      <td>346.11, -207.85, 164.32, 67.36, -2.98</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>346.069484</td>\n",
       "      <td>125502.852876</td>\n",
       "      <td>0.364326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model Regression Type Best Alpha Best L1 Ratio  ... Split   RMSE Mean       MSE Mean   R2 Mean\n",
       "0   All_Features_Linear          Linear         NA            NA  ...  CV-5  342.139591  121136.310318  0.343495\n",
       "1       Ridge_All_Tuned           Ridge   3.393222            NA  ...  CV-5  338.640502  118715.693998  0.363510\n",
       "2       Lasso_All_Tuned           Lasso   2.222996            NA  ...  CV-5  339.164091  119077.752512  0.364623\n",
       "3  ElasticNet_All_Tuned      ElasticNet        0.1          0.75  ...  CV-5  338.523418  118776.366833  0.366784\n",
       "4           Hits_Linear          Linear         NA            NA  ...  CV-5  408.435433  173088.972864  0.122213\n",
       "5            Hits_Ridge           Ridge  24.420531            NA  ...  CV-5  407.841429  172580.243054  0.128410\n",
       "6            Hits_Lasso           Lasso   5.963623            NA  ...  CV-5  408.373539  173047.782853  0.123640\n",
       "7       Hits_Elasticnet      ElasticNet   0.132571             0  ...  CV-5  407.830061  172569.673986  0.128863\n",
       "8           Top5_Linear          Linear         NA            NA  ...  CV-5  346.069484  125502.852876  0.364326\n",
       "\n",
       "[9 rows x 11 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_linear_regression(\"Top5_Linear\", features=['CRuns', 'Hits', 'AtBat', 'CRBI', 'CWalks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "e183a826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Regression Type</th>\n",
       "      <th>Best Alpha</th>\n",
       "      <th>Best L1 Ratio</th>\n",
       "      <th>Variables Used</th>\n",
       "      <th>Top 10 Variables</th>\n",
       "      <th>Top 10 Coefficients</th>\n",
       "      <th>Split</th>\n",
       "      <th>RMSE Mean</th>\n",
       "      <th>MSE Mean</th>\n",
       "      <th>R2 Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All_Features_Linear</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>All</td>\n",
       "      <td>CRuns, CAtBat, Hits, AtBat, CRBI, CWalks, Walk...</td>\n",
       "      <td>480.75, -391.04, 337.83, -291.09, 260.69, -213...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>342.139591</td>\n",
       "      <td>121136.310318</td>\n",
       "      <td>0.343495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge_All_Tuned</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>3.393222</td>\n",
       "      <td>NA</td>\n",
       "      <td>All</td>\n",
       "      <td>Hits, AtBat, CRuns, CWalks, CHits, Division_W,...</td>\n",
       "      <td>233.42, -218.94, 203.43, -146.12, 119.93, -118...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>338.640502</td>\n",
       "      <td>118715.693998</td>\n",
       "      <td>0.363510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso_All_Tuned</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>2.222996</td>\n",
       "      <td>NA</td>\n",
       "      <td>All</td>\n",
       "      <td>Hits, AtBat, CRuns, CWalks, CRBI, Division_W, ...</td>\n",
       "      <td>269.91, -249.36, 233.40, -153.72, 122.59, -114...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>339.164091</td>\n",
       "      <td>119077.752512</td>\n",
       "      <td>0.364623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ElasticNet_All_Tuned</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>All</td>\n",
       "      <td>Hits, AtBat, CRuns, Division_W, CWalks, CHits,...</td>\n",
       "      <td>183.90, -168.73, 147.09, -115.34, -114.21, 105...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>338.523418</td>\n",
       "      <td>118776.366833</td>\n",
       "      <td>0.366784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hits_Linear</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>Hits</td>\n",
       "      <td>197.52</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>408.435433</td>\n",
       "      <td>173088.972864</td>\n",
       "      <td>0.122213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hits_Ridge</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>24.420531</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>Hits</td>\n",
       "      <td>180.74</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>407.841429</td>\n",
       "      <td>172580.243054</td>\n",
       "      <td>0.128410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hits_Lasso</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>5.963623</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>Hits</td>\n",
       "      <td>191.55</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>408.373539</td>\n",
       "      <td>173047.782853</td>\n",
       "      <td>0.123640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hits_Elasticnet</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.132571</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hits</td>\n",
       "      <td>174.40</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>407.830061</td>\n",
       "      <td>172569.673986</td>\n",
       "      <td>0.128863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Top5_Linear</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>5</td>\n",
       "      <td>Hits, AtBat, CRBI, CRuns, CWalks</td>\n",
       "      <td>346.11, -207.85, 164.32, 67.36, -2.98</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>346.069484</td>\n",
       "      <td>125502.852876</td>\n",
       "      <td>0.364326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Top5_Ridge</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>2.947052</td>\n",
       "      <td>NA</td>\n",
       "      <td>5</td>\n",
       "      <td>Hits, CRBI, AtBat, CRuns, CWalks</td>\n",
       "      <td>279.81, 153.36, -142.16, 76.24, -2.03</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>344.998216</td>\n",
       "      <td>124956.375184</td>\n",
       "      <td>0.369658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model Regression Type Best Alpha Best L1 Ratio  ... Split   RMSE Mean       MSE Mean   R2 Mean\n",
       "0   All_Features_Linear          Linear         NA            NA  ...  CV-5  342.139591  121136.310318  0.343495\n",
       "1       Ridge_All_Tuned           Ridge   3.393222            NA  ...  CV-5  338.640502  118715.693998  0.363510\n",
       "2       Lasso_All_Tuned           Lasso   2.222996            NA  ...  CV-5  339.164091  119077.752512  0.364623\n",
       "3  ElasticNet_All_Tuned      ElasticNet        0.1          0.75  ...  CV-5  338.523418  118776.366833  0.366784\n",
       "4           Hits_Linear          Linear         NA            NA  ...  CV-5  408.435433  173088.972864  0.122213\n",
       "5            Hits_Ridge           Ridge  24.420531            NA  ...  CV-5  407.841429  172580.243054  0.128410\n",
       "6            Hits_Lasso           Lasso   5.963623            NA  ...  CV-5  408.373539  173047.782853  0.123640\n",
       "7       Hits_Elasticnet      ElasticNet   0.132571             0  ...  CV-5  407.830061  172569.673986  0.128863\n",
       "8           Top5_Linear          Linear         NA            NA  ...  CV-5  346.069484  125502.852876  0.364326\n",
       "9            Top5_Ridge           Ridge   2.947052            NA  ...  CV-5  344.998216  124956.375184  0.369658\n",
       "\n",
       "[10 rows x 11 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_ridge_regression(\"Top5_Ridge\", features=['CRuns', 'Hits', 'AtBat', 'CRBI', 'CWalks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "ed3be9d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Regression Type</th>\n",
       "      <th>Best Alpha</th>\n",
       "      <th>Best L1 Ratio</th>\n",
       "      <th>Variables Used</th>\n",
       "      <th>Top 10 Variables</th>\n",
       "      <th>Top 10 Coefficients</th>\n",
       "      <th>Split</th>\n",
       "      <th>RMSE Mean</th>\n",
       "      <th>MSE Mean</th>\n",
       "      <th>R2 Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All_Features_Linear</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>All</td>\n",
       "      <td>CRuns, CAtBat, Hits, AtBat, CRBI, CWalks, Walk...</td>\n",
       "      <td>480.75, -391.04, 337.83, -291.09, 260.69, -213...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>342.139591</td>\n",
       "      <td>121136.310318</td>\n",
       "      <td>0.343495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge_All_Tuned</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>3.393222</td>\n",
       "      <td>NA</td>\n",
       "      <td>All</td>\n",
       "      <td>Hits, AtBat, CRuns, CWalks, CHits, Division_W,...</td>\n",
       "      <td>233.42, -218.94, 203.43, -146.12, 119.93, -118...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>338.640502</td>\n",
       "      <td>118715.693998</td>\n",
       "      <td>0.363510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso_All_Tuned</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>2.222996</td>\n",
       "      <td>NA</td>\n",
       "      <td>All</td>\n",
       "      <td>Hits, AtBat, CRuns, CWalks, CRBI, Division_W, ...</td>\n",
       "      <td>269.91, -249.36, 233.40, -153.72, 122.59, -114...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>339.164091</td>\n",
       "      <td>119077.752512</td>\n",
       "      <td>0.364623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ElasticNet_All_Tuned</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>All</td>\n",
       "      <td>Hits, AtBat, CRuns, Division_W, CWalks, CHits,...</td>\n",
       "      <td>183.90, -168.73, 147.09, -115.34, -114.21, 105...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>338.523418</td>\n",
       "      <td>118776.366833</td>\n",
       "      <td>0.366784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hits_Linear</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>Hits</td>\n",
       "      <td>197.52</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>408.435433</td>\n",
       "      <td>173088.972864</td>\n",
       "      <td>0.122213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hits_Ridge</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>24.420531</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>Hits</td>\n",
       "      <td>180.74</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>407.841429</td>\n",
       "      <td>172580.243054</td>\n",
       "      <td>0.128410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hits_Lasso</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>5.963623</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>Hits</td>\n",
       "      <td>191.55</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>408.373539</td>\n",
       "      <td>173047.782853</td>\n",
       "      <td>0.123640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hits_Elasticnet</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.132571</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hits</td>\n",
       "      <td>174.40</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>407.830061</td>\n",
       "      <td>172569.673986</td>\n",
       "      <td>0.128863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Top5_Linear</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>5</td>\n",
       "      <td>Hits, AtBat, CRBI, CRuns, CWalks</td>\n",
       "      <td>346.11, -207.85, 164.32, 67.36, -2.98</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>346.069484</td>\n",
       "      <td>125502.852876</td>\n",
       "      <td>0.364326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Top5_Ridge</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>2.947052</td>\n",
       "      <td>NA</td>\n",
       "      <td>5</td>\n",
       "      <td>Hits, CRBI, AtBat, CRuns, CWalks</td>\n",
       "      <td>279.81, 153.36, -142.16, 76.24, -2.03</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>344.998216</td>\n",
       "      <td>124956.375184</td>\n",
       "      <td>0.369658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Top5_Lasso</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>1.264855</td>\n",
       "      <td>NA</td>\n",
       "      <td>5</td>\n",
       "      <td>Hits, AtBat, CRBI, CRuns, CWalks</td>\n",
       "      <td>311.42, -172.58, 162.16, 65.29, 0.00</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>345.470227</td>\n",
       "      <td>125285.393348</td>\n",
       "      <td>0.367334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model Regression Type Best Alpha Best L1 Ratio  ... Split   RMSE Mean       MSE Mean   R2 Mean\n",
       "0    All_Features_Linear          Linear         NA            NA  ...  CV-5  342.139591  121136.310318  0.343495\n",
       "1        Ridge_All_Tuned           Ridge   3.393222            NA  ...  CV-5  338.640502  118715.693998  0.363510\n",
       "2        Lasso_All_Tuned           Lasso   2.222996            NA  ...  CV-5  339.164091  119077.752512  0.364623\n",
       "3   ElasticNet_All_Tuned      ElasticNet        0.1          0.75  ...  CV-5  338.523418  118776.366833  0.366784\n",
       "4            Hits_Linear          Linear         NA            NA  ...  CV-5  408.435433  173088.972864  0.122213\n",
       "5             Hits_Ridge           Ridge  24.420531            NA  ...  CV-5  407.841429  172580.243054  0.128410\n",
       "6             Hits_Lasso           Lasso   5.963623            NA  ...  CV-5  408.373539  173047.782853  0.123640\n",
       "7        Hits_Elasticnet      ElasticNet   0.132571             0  ...  CV-5  407.830061  172569.673986  0.128863\n",
       "8            Top5_Linear          Linear         NA            NA  ...  CV-5  346.069484  125502.852876  0.364326\n",
       "9             Top5_Ridge           Ridge   2.947052            NA  ...  CV-5  344.998216  124956.375184  0.369658\n",
       "10            Top5_Lasso           Lasso   1.264855            NA  ...  CV-5  345.470227  125285.393348  0.367334\n",
       "\n",
       "[11 rows x 11 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_lasso_regression(\"Top5_Lasso\", features=['CRuns', 'Hits', 'AtBat', 'CRBI', 'CWalks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "80bfd0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.445e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.121e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.295e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.084e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.335e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.453e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.125e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.301e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.091e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.342e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.461e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.129e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.308e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.099e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.349e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.470e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.134e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.315e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.108e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.356e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.480e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.140e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.323e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.118e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.365e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.490e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.146e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.331e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.128e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.374e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.501e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.152e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.340e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.139e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.383e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.513e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.160e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.349e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.152e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.394e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.525e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.168e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.359e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.165e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.406e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.539e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.177e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.371e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.180e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.419e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.554e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.187e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.383e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.196e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.433e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.571e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.198e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.396e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.214e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.449e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.589e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.210e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.411e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.233e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.466e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.608e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.224e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.427e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.255e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.485e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.629e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.238e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.444e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.278e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.506e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.651e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.255e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.463e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.528e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.675e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.272e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.483e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.329e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.552e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.700e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.290e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.504e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.358e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.577e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.727e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.310e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.526e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.388e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.605e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.755e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.331e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.550e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.421e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.633e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.785e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.354e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.575e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.455e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.664e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.815e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.377e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.601e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.490e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.695e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.400e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.526e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.727e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.878e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.424e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.654e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.563e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.910e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.449e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.682e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.794e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.942e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.474e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.709e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.638e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.828e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.973e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.498e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.736e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.675e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.861e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.003e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.522e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.762e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.711e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.893e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.033e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.545e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.788e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.747e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.925e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.062e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.568e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.812e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.781e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.956e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.089e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.589e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.836e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.814e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.985e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.114e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.609e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.858e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.845e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.013e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.138e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.874e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.160e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.646e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.898e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.901e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.064e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.181e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.663e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.916e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.926e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.086e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.200e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.678e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.933e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.949e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.107e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.217e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.692e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.948e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.970e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.126e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.704e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.990e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.143e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.247e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.716e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.974e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.007e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.159e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.259e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.726e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.985e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.023e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.173e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.270e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.995e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.037e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.185e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.281e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.743e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.004e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.049e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.197e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.289e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.750e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.012e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.060e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.207e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.297e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.757e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.019e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.070e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.216e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.304e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.763e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.025e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.079e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.223e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.311e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.768e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.030e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.087e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.230e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.316e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.772e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.035e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.093e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.237e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.321e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.776e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.039e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.099e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.242e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.325e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.780e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.043e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.105e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.247e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.329e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.783e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.046e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.109e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.251e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Regression Type</th>\n",
       "      <th>Best Alpha</th>\n",
       "      <th>Best L1 Ratio</th>\n",
       "      <th>Variables Used</th>\n",
       "      <th>Top 10 Variables</th>\n",
       "      <th>Top 10 Coefficients</th>\n",
       "      <th>Split</th>\n",
       "      <th>RMSE Mean</th>\n",
       "      <th>MSE Mean</th>\n",
       "      <th>R2 Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All_Features_Linear</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>All</td>\n",
       "      <td>CRuns, CAtBat, Hits, AtBat, CRBI, CWalks, Walk...</td>\n",
       "      <td>480.75, -391.04, 337.83, -291.09, 260.69, -213...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>342.139591</td>\n",
       "      <td>121136.310318</td>\n",
       "      <td>0.343495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge_All_Tuned</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>3.393222</td>\n",
       "      <td>NA</td>\n",
       "      <td>All</td>\n",
       "      <td>Hits, AtBat, CRuns, CWalks, CHits, Division_W,...</td>\n",
       "      <td>233.42, -218.94, 203.43, -146.12, 119.93, -118...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>338.640502</td>\n",
       "      <td>118715.693998</td>\n",
       "      <td>0.363510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso_All_Tuned</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>2.222996</td>\n",
       "      <td>NA</td>\n",
       "      <td>All</td>\n",
       "      <td>Hits, AtBat, CRuns, CWalks, CRBI, Division_W, ...</td>\n",
       "      <td>269.91, -249.36, 233.40, -153.72, 122.59, -114...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>339.164091</td>\n",
       "      <td>119077.752512</td>\n",
       "      <td>0.364623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ElasticNet_All_Tuned</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>All</td>\n",
       "      <td>Hits, AtBat, CRuns, Division_W, CWalks, CHits,...</td>\n",
       "      <td>183.90, -168.73, 147.09, -115.34, -114.21, 105...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>338.523418</td>\n",
       "      <td>118776.366833</td>\n",
       "      <td>0.366784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hits_Linear</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>Hits</td>\n",
       "      <td>197.52</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>408.435433</td>\n",
       "      <td>173088.972864</td>\n",
       "      <td>0.122213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hits_Ridge</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>24.420531</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>Hits</td>\n",
       "      <td>180.74</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>407.841429</td>\n",
       "      <td>172580.243054</td>\n",
       "      <td>0.128410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hits_Lasso</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>5.963623</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>Hits</td>\n",
       "      <td>191.55</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>408.373539</td>\n",
       "      <td>173047.782853</td>\n",
       "      <td>0.123640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hits_Elasticnet</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.132571</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hits</td>\n",
       "      <td>174.40</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>407.830061</td>\n",
       "      <td>172569.673986</td>\n",
       "      <td>0.128863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Top5_Linear</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>5</td>\n",
       "      <td>Hits, AtBat, CRBI, CRuns, CWalks</td>\n",
       "      <td>346.11, -207.85, 164.32, 67.36, -2.98</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>346.069484</td>\n",
       "      <td>125502.852876</td>\n",
       "      <td>0.364326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Top5_Ridge</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>2.947052</td>\n",
       "      <td>NA</td>\n",
       "      <td>5</td>\n",
       "      <td>Hits, CRBI, AtBat, CRuns, CWalks</td>\n",
       "      <td>279.81, 153.36, -142.16, 76.24, -2.03</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>344.998216</td>\n",
       "      <td>124956.375184</td>\n",
       "      <td>0.369658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Top5_Lasso</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>1.264855</td>\n",
       "      <td>NA</td>\n",
       "      <td>5</td>\n",
       "      <td>Hits, AtBat, CRBI, CRuns, CWalks</td>\n",
       "      <td>311.42, -172.58, 162.16, 65.29, 0.00</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>345.470227</td>\n",
       "      <td>125285.393348</td>\n",
       "      <td>0.367334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Top5_Elasticnet</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>5</td>\n",
       "      <td>Hits, CRBI, AtBat, CRuns, CWalks</td>\n",
       "      <td>230.78, 143.88, -93.52, 80.66, 1.72</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>344.974241</td>\n",
       "      <td>125057.212316</td>\n",
       "      <td>0.370411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model Regression Type Best Alpha Best L1 Ratio  ... Split   RMSE Mean       MSE Mean   R2 Mean\n",
       "0    All_Features_Linear          Linear         NA            NA  ...  CV-5  342.139591  121136.310318  0.343495\n",
       "1        Ridge_All_Tuned           Ridge   3.393222            NA  ...  CV-5  338.640502  118715.693998  0.363510\n",
       "2        Lasso_All_Tuned           Lasso   2.222996            NA  ...  CV-5  339.164091  119077.752512  0.364623\n",
       "3   ElasticNet_All_Tuned      ElasticNet        0.1          0.75  ...  CV-5  338.523418  118776.366833  0.366784\n",
       "4            Hits_Linear          Linear         NA            NA  ...  CV-5  408.435433  173088.972864  0.122213\n",
       "5             Hits_Ridge           Ridge  24.420531            NA  ...  CV-5  407.841429  172580.243054  0.128410\n",
       "6             Hits_Lasso           Lasso   5.963623            NA  ...  CV-5  408.373539  173047.782853  0.123640\n",
       "7        Hits_Elasticnet      ElasticNet   0.132571             0  ...  CV-5  407.830061  172569.673986  0.128863\n",
       "8            Top5_Linear          Linear         NA            NA  ...  CV-5  346.069484  125502.852876  0.364326\n",
       "9             Top5_Ridge           Ridge   2.947052            NA  ...  CV-5  344.998216  124956.375184  0.369658\n",
       "10            Top5_Lasso           Lasso   1.264855            NA  ...  CV-5  345.470227  125285.393348  0.367334\n",
       "11       Top5_Elasticnet      ElasticNet        0.1          0.75  ...  CV-5  344.974241  125057.212316  0.370411\n",
       "\n",
       "[12 rows x 11 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_elasticnet_regression(\"Top5_Elasticnet\", features=['CRuns', 'Hits', 'AtBat', 'CRBI', 'CWalks'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8433280",
   "metadata": {},
   "source": [
    "### Interpretation \n",
    "\n",
    "In this case Ridge took the lead but not by much all the MSEs are not too different between the models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61f2a0e",
   "metadata": {},
   "source": [
    "## 3.  Using the five best numeric variables *and* their interactions with the one best categorical variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3699f936",
   "metadata": {},
   "source": [
    "### Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "7c084f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Regression Type</th>\n",
       "      <th>Best Alpha</th>\n",
       "      <th>Best L1 Ratio</th>\n",
       "      <th>Variables Used</th>\n",
       "      <th>Top 10 Variables</th>\n",
       "      <th>Top 10 Coefficients</th>\n",
       "      <th>Split</th>\n",
       "      <th>RMSE Mean</th>\n",
       "      <th>MSE Mean</th>\n",
       "      <th>R2 Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All_Features_Linear</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>All</td>\n",
       "      <td>CRuns, CAtBat, Hits, AtBat, CRBI, CWalks, Walk...</td>\n",
       "      <td>480.75, -391.04, 337.83, -291.09, 260.69, -213...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>342.139591</td>\n",
       "      <td>121136.310318</td>\n",
       "      <td>0.343495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge_All_Tuned</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>3.393222</td>\n",
       "      <td>NA</td>\n",
       "      <td>All</td>\n",
       "      <td>Hits, AtBat, CRuns, CWalks, CHits, Division_W,...</td>\n",
       "      <td>233.42, -218.94, 203.43, -146.12, 119.93, -118...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>338.640502</td>\n",
       "      <td>118715.693998</td>\n",
       "      <td>0.363510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso_All_Tuned</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>2.222996</td>\n",
       "      <td>NA</td>\n",
       "      <td>All</td>\n",
       "      <td>Hits, AtBat, CRuns, CWalks, CRBI, Division_W, ...</td>\n",
       "      <td>269.91, -249.36, 233.40, -153.72, 122.59, -114...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>339.164091</td>\n",
       "      <td>119077.752512</td>\n",
       "      <td>0.364623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ElasticNet_All_Tuned</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>All</td>\n",
       "      <td>Hits, AtBat, CRuns, Division_W, CWalks, CHits,...</td>\n",
       "      <td>183.90, -168.73, 147.09, -115.34, -114.21, 105...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>338.523418</td>\n",
       "      <td>118776.366833</td>\n",
       "      <td>0.366784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hits_Linear</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>Hits</td>\n",
       "      <td>197.52</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>408.435433</td>\n",
       "      <td>173088.972864</td>\n",
       "      <td>0.122213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hits_Ridge</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>24.420531</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>Hits</td>\n",
       "      <td>180.74</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>407.841429</td>\n",
       "      <td>172580.243054</td>\n",
       "      <td>0.128410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hits_Lasso</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>5.963623</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>Hits</td>\n",
       "      <td>191.55</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>408.373539</td>\n",
       "      <td>173047.782853</td>\n",
       "      <td>0.123640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hits_Elasticnet</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.132571</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hits</td>\n",
       "      <td>174.40</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>407.830061</td>\n",
       "      <td>172569.673986</td>\n",
       "      <td>0.128863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Top5_Linear</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>5</td>\n",
       "      <td>Hits, AtBat, CRBI, CRuns, CWalks</td>\n",
       "      <td>346.11, -207.85, 164.32, 67.36, -2.98</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>346.069484</td>\n",
       "      <td>125502.852876</td>\n",
       "      <td>0.364326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Top5_Ridge</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>2.947052</td>\n",
       "      <td>NA</td>\n",
       "      <td>5</td>\n",
       "      <td>Hits, CRBI, AtBat, CRuns, CWalks</td>\n",
       "      <td>279.81, 153.36, -142.16, 76.24, -2.03</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>344.998216</td>\n",
       "      <td>124956.375184</td>\n",
       "      <td>0.369658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Top5_Lasso</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>1.264855</td>\n",
       "      <td>NA</td>\n",
       "      <td>5</td>\n",
       "      <td>Hits, AtBat, CRBI, CRuns, CWalks</td>\n",
       "      <td>311.42, -172.58, 162.16, 65.29, 0.00</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>345.470227</td>\n",
       "      <td>125285.393348</td>\n",
       "      <td>0.367334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Top5_Elasticnet</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>5</td>\n",
       "      <td>Hits, CRBI, AtBat, CRuns, CWalks</td>\n",
       "      <td>230.78, 143.88, -93.52, 80.66, 1.72</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>344.974241</td>\n",
       "      <td>125057.212316</td>\n",
       "      <td>0.370411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Lin_Num_Cat_Interact</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>11</td>\n",
       "      <td>AtBat_x_Division, Hits_x_Division, Hits, AtBat...</td>\n",
       "      <td>517.14, -489.78, 456.44, -327.22, 286.34, -169...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>355.297221</td>\n",
       "      <td>132054.760135</td>\n",
       "      <td>0.309611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model Regression Type Best Alpha Best L1 Ratio  ... Split   RMSE Mean       MSE Mean   R2 Mean\n",
       "0    All_Features_Linear          Linear         NA            NA  ...  CV-5  342.139591  121136.310318  0.343495\n",
       "1        Ridge_All_Tuned           Ridge   3.393222            NA  ...  CV-5  338.640502  118715.693998  0.363510\n",
       "2        Lasso_All_Tuned           Lasso   2.222996            NA  ...  CV-5  339.164091  119077.752512  0.364623\n",
       "3   ElasticNet_All_Tuned      ElasticNet        0.1          0.75  ...  CV-5  338.523418  118776.366833  0.366784\n",
       "4            Hits_Linear          Linear         NA            NA  ...  CV-5  408.435433  173088.972864  0.122213\n",
       "5             Hits_Ridge           Ridge  24.420531            NA  ...  CV-5  407.841429  172580.243054  0.128410\n",
       "6             Hits_Lasso           Lasso   5.963623            NA  ...  CV-5  408.373539  173047.782853  0.123640\n",
       "7        Hits_Elasticnet      ElasticNet   0.132571             0  ...  CV-5  407.830061  172569.673986  0.128863\n",
       "8            Top5_Linear          Linear         NA            NA  ...  CV-5  346.069484  125502.852876  0.364326\n",
       "9             Top5_Ridge           Ridge   2.947052            NA  ...  CV-5  344.998216  124956.375184  0.369658\n",
       "10            Top5_Lasso           Lasso   1.264855            NA  ...  CV-5  345.470227  125285.393348  0.367334\n",
       "11       Top5_Elasticnet      ElasticNet        0.1          0.75  ...  CV-5  344.974241  125057.212316  0.370411\n",
       "12  Lin_Num_Cat_Interact          Linear         NA            NA  ...  CV-5  355.297221  132054.760135  0.309611\n",
       "\n",
       "[13 rows x 11 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Name\n",
    "model_name = \"Lin_Num_Cat_Interact\"\n",
    "regression_type = \"Linear\"  \n",
    "\n",
    "# Features\n",
    "numeric_vars = ['CRuns', 'Hits', 'AtBat', 'CRBI', 'CWalks']\n",
    "cat_var = 'Division'\n",
    "\n",
    "# Select and Subset\n",
    "X_subset = X[numeric_vars + [cat_var]].copy()\n",
    "X_subset['Division_Binary'] = (X_subset['Division'] == 'W').astype(int)\n",
    "\n",
    "# Create interaction\n",
    "X_subset['CRuns_x_Division'] = X_subset['CRuns'] * X_subset['Division_Binary']\n",
    "X_subset['Hits_x_Division'] = X_subset['Hits'] * X_subset['Division_Binary']\n",
    "X_subset['AtBat_x_Division'] = X_subset['AtBat'] * X_subset['Division_Binary']\n",
    "X_subset['CRBI_x_Division'] = X_subset['CRBI'] * X_subset['Division_Binary']\n",
    "X_subset['CWalks_x_Division'] = X_subset['CWalks'] * X_subset['Division_Binary']\n",
    "\n",
    "# Drop the temporary Division_Binary column\n",
    "X_subset = X_subset.drop(columns=['Division_Binary'])\n",
    "\n",
    "# Pipeline \n",
    "pipe = Pipeline([\n",
    "    (\"preprocess\", ct),\n",
    "    (\"linear_regression\", LinearRegression())\n",
    "])\n",
    "\n",
    "# Fit and add to Library\n",
    "pipe.fit(X_subset, y)\n",
    "model_library[model_name] = pipe\n",
    "\n",
    "# Get top 10 coefficients\n",
    "feature_names = pipe.named_steps['preprocess'].get_feature_names_out()\n",
    "coefficients = pipe.named_steps['linear_regression'].coef_\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    'Variable': feature_names,\n",
    "    'Coefficient': coefficients\n",
    "}).sort_values('Coefficient', key=abs, ascending=False).head(10)\n",
    "\n",
    "# Metrics Calculation \n",
    "rmse = cross_val_score(pipe, X_subset, y, cv=5, scoring='neg_root_mean_squared_error')\n",
    "mse = cross_val_score(pipe, X_subset, y, cv=5, scoring='neg_mean_squared_error')\n",
    "r2 = cross_val_score(pipe, X_subset, y, cv=5, scoring='r2')\n",
    "\n",
    "# Metrics Storage \n",
    "records.append({\n",
    "    \"Model\": model_name,\n",
    "    \"Regression Type\": regression_type,\n",
    "    \"Best Alpha\": \"NA\", \n",
    "    \"Best L1 Ratio\": \"NA\",\n",
    "    \"Variables Used\": len(X_subset.columns),\n",
    "    \"Top 10 Variables\": \", \".join(coef_df['Variable'].head(10).tolist()),\n",
    "    \"Top 10 Coefficients\": \", \".join([f\"{c:.2f}\" for c in coef_df['Coefficient'].head(10).tolist()]),\n",
    "    \"Split\": \"CV-5\",\n",
    "    \"RMSE Mean\": -rmse.mean(),\n",
    "    \"MSE Mean\": -mse.mean(),\n",
    "    \"R2 Mean\": r2.mean()\n",
    "})\n",
    "\n",
    "# Display\n",
    "cumulative_models = pd.DataFrame(records)\n",
    "cumulative_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a46b48",
   "metadata": {},
   "source": [
    "### Ridge Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "5e8c4ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Regression Type</th>\n",
       "      <th>Best Alpha</th>\n",
       "      <th>Best L1 Ratio</th>\n",
       "      <th>Variables Used</th>\n",
       "      <th>Top 10 Variables</th>\n",
       "      <th>Top 10 Coefficients</th>\n",
       "      <th>Split</th>\n",
       "      <th>RMSE Mean</th>\n",
       "      <th>MSE Mean</th>\n",
       "      <th>R2 Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All_Features_Linear</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>All</td>\n",
       "      <td>CRuns, CAtBat, Hits, AtBat, CRBI, CWalks, Walk...</td>\n",
       "      <td>480.75, -391.04, 337.83, -291.09, 260.69, -213...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>342.139591</td>\n",
       "      <td>121136.310318</td>\n",
       "      <td>0.343495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge_All_Tuned</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>3.393222</td>\n",
       "      <td>NA</td>\n",
       "      <td>All</td>\n",
       "      <td>Hits, AtBat, CRuns, CWalks, CHits, Division_W,...</td>\n",
       "      <td>233.42, -218.94, 203.43, -146.12, 119.93, -118...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>338.640502</td>\n",
       "      <td>118715.693998</td>\n",
       "      <td>0.363510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso_All_Tuned</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>2.222996</td>\n",
       "      <td>NA</td>\n",
       "      <td>All</td>\n",
       "      <td>Hits, AtBat, CRuns, CWalks, CRBI, Division_W, ...</td>\n",
       "      <td>269.91, -249.36, 233.40, -153.72, 122.59, -114...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>339.164091</td>\n",
       "      <td>119077.752512</td>\n",
       "      <td>0.364623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ElasticNet_All_Tuned</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>All</td>\n",
       "      <td>Hits, AtBat, CRuns, Division_W, CWalks, CHits,...</td>\n",
       "      <td>183.90, -168.73, 147.09, -115.34, -114.21, 105...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>338.523418</td>\n",
       "      <td>118776.366833</td>\n",
       "      <td>0.366784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hits_Linear</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>Hits</td>\n",
       "      <td>197.52</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>408.435433</td>\n",
       "      <td>173088.972864</td>\n",
       "      <td>0.122213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hits_Ridge</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>24.420531</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>Hits</td>\n",
       "      <td>180.74</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>407.841429</td>\n",
       "      <td>172580.243054</td>\n",
       "      <td>0.128410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hits_Lasso</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>5.963623</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>Hits</td>\n",
       "      <td>191.55</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>408.373539</td>\n",
       "      <td>173047.782853</td>\n",
       "      <td>0.123640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hits_Elasticnet</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.132571</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hits</td>\n",
       "      <td>174.40</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>407.830061</td>\n",
       "      <td>172569.673986</td>\n",
       "      <td>0.128863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Top5_Linear</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>5</td>\n",
       "      <td>Hits, AtBat, CRBI, CRuns, CWalks</td>\n",
       "      <td>346.11, -207.85, 164.32, 67.36, -2.98</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>346.069484</td>\n",
       "      <td>125502.852876</td>\n",
       "      <td>0.364326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Top5_Ridge</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>2.947052</td>\n",
       "      <td>NA</td>\n",
       "      <td>5</td>\n",
       "      <td>Hits, CRBI, AtBat, CRuns, CWalks</td>\n",
       "      <td>279.81, 153.36, -142.16, 76.24, -2.03</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>344.998216</td>\n",
       "      <td>124956.375184</td>\n",
       "      <td>0.369658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Top5_Lasso</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>1.264855</td>\n",
       "      <td>NA</td>\n",
       "      <td>5</td>\n",
       "      <td>Hits, AtBat, CRBI, CRuns, CWalks</td>\n",
       "      <td>311.42, -172.58, 162.16, 65.29, 0.00</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>345.470227</td>\n",
       "      <td>125285.393348</td>\n",
       "      <td>0.367334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Top5_Elasticnet</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>5</td>\n",
       "      <td>Hits, CRBI, AtBat, CRuns, CWalks</td>\n",
       "      <td>230.78, 143.88, -93.52, 80.66, 1.72</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>344.974241</td>\n",
       "      <td>125057.212316</td>\n",
       "      <td>0.370411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Lin_Num_Cat_Interact</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>11</td>\n",
       "      <td>AtBat_x_Division, Hits_x_Division, Hits, AtBat...</td>\n",
       "      <td>517.14, -489.78, 456.44, -327.22, 286.34, -169...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>355.297221</td>\n",
       "      <td>132054.760135</td>\n",
       "      <td>0.309611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Ridge_Num_Cat_Interact</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>37.275937</td>\n",
       "      <td>NA</td>\n",
       "      <td>11</td>\n",
       "      <td>CRBI, Hits, CRuns, CWalks_x_Division, CWalks, ...</td>\n",
       "      <td>130.58, 114.41, 94.29, -45.72, 35.89, -18.90, ...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>341.543568</td>\n",
       "      <td>121538.755636</td>\n",
       "      <td>0.381395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model Regression Type Best Alpha Best L1 Ratio  ... Split   RMSE Mean       MSE Mean   R2 Mean\n",
       "0      All_Features_Linear          Linear         NA            NA  ...  CV-5  342.139591  121136.310318  0.343495\n",
       "1          Ridge_All_Tuned           Ridge   3.393222            NA  ...  CV-5  338.640502  118715.693998  0.363510\n",
       "2          Lasso_All_Tuned           Lasso   2.222996            NA  ...  CV-5  339.164091  119077.752512  0.364623\n",
       "3     ElasticNet_All_Tuned      ElasticNet        0.1          0.75  ...  CV-5  338.523418  118776.366833  0.366784\n",
       "4              Hits_Linear          Linear         NA            NA  ...  CV-5  408.435433  173088.972864  0.122213\n",
       "5               Hits_Ridge           Ridge  24.420531            NA  ...  CV-5  407.841429  172580.243054  0.128410\n",
       "6               Hits_Lasso           Lasso   5.963623            NA  ...  CV-5  408.373539  173047.782853  0.123640\n",
       "7          Hits_Elasticnet      ElasticNet   0.132571             0  ...  CV-5  407.830061  172569.673986  0.128863\n",
       "8              Top5_Linear          Linear         NA            NA  ...  CV-5  346.069484  125502.852876  0.364326\n",
       "9               Top5_Ridge           Ridge   2.947052            NA  ...  CV-5  344.998216  124956.375184  0.369658\n",
       "10              Top5_Lasso           Lasso   1.264855            NA  ...  CV-5  345.470227  125285.393348  0.367334\n",
       "11         Top5_Elasticnet      ElasticNet        0.1          0.75  ...  CV-5  344.974241  125057.212316  0.370411\n",
       "12    Lin_Num_Cat_Interact          Linear         NA            NA  ...  CV-5  355.297221  132054.760135  0.309611\n",
       "13  Ridge_Num_Cat_Interact           Ridge  37.275937            NA  ...  CV-5  341.543568  121538.755636  0.381395\n",
       "\n",
       "[14 rows x 11 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Name\n",
    "model_name = \"Ridge_Num_Cat_Interact\"\n",
    "regression_type = \"Ridge\"  \n",
    "\n",
    "# Features\n",
    "numeric_vars = ['CRuns', 'Hits', 'AtBat', 'CRBI', 'CWalks']\n",
    "cat_var = 'Division'\n",
    "\n",
    "# Select and Subset\n",
    "X_subset = X[numeric_vars + [cat_var]].copy()\n",
    "X_subset['Division_Binary'] = (X_subset['Division'] == 'W').astype(int)\n",
    "\n",
    "# Create interaction\n",
    "X_subset['CRuns_x_Division'] = X_subset['CRuns'] * X_subset['Division_Binary']\n",
    "X_subset['Hits_x_Division'] = X_subset['Hits'] * X_subset['Division_Binary']\n",
    "X_subset['AtBat_x_Division'] = X_subset['AtBat'] * X_subset['Division_Binary']\n",
    "X_subset['CRBI_x_Division'] = X_subset['CRBI'] * X_subset['Division_Binary']\n",
    "X_subset['CWalks_x_Division'] = X_subset['CWalks'] * X_subset['Division_Binary']\n",
    "\n",
    "# Drop the temporary Division_Binary column\n",
    "X_subset = X_subset.drop(columns=['Division_Binary'])\n",
    "\n",
    "# Pipeline with Ridge\n",
    "pipe = Pipeline([\n",
    "    (\"preprocess\", ct),\n",
    "    (\"ridge\", Ridge())  \n",
    "])\n",
    "\n",
    "# GridSearchCV \n",
    "param_grid = {'ridge__alpha': np.logspace(-1, 2, 50)}\n",
    "gscv = GridSearchCV(pipe, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "gscv.fit(X_subset, y)\n",
    "\n",
    "# Add best model to Library\n",
    "model_library[model_name] = gscv.best_estimator_\n",
    "\n",
    "# Get best alpha\n",
    "best_alpha = gscv.best_params_['ridge__alpha']\n",
    "\n",
    "# Get top 10 coefficients\n",
    "feature_names = gscv.best_estimator_.named_steps['preprocess'].get_feature_names_out()\n",
    "coefficients = gscv.best_estimator_.named_steps['ridge'].coef_\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    'Variable': feature_names,\n",
    "    'Coefficient': coefficients\n",
    "}).sort_values('Coefficient', key=abs, ascending=False).head(10)\n",
    "\n",
    "# Metrics Calculation using best model\n",
    "rmse = cross_val_score(gscv.best_estimator_, X_subset, y, cv=5, scoring='neg_root_mean_squared_error')\n",
    "mse = cross_val_score(gscv.best_estimator_, X_subset, y, cv=5, scoring='neg_mean_squared_error')\n",
    "r2 = cross_val_score(gscv.best_estimator_, X_subset, y, cv=5, scoring='r2')\n",
    "\n",
    "# Metrics Storage \n",
    "records.append({\n",
    "    \"Model\": model_name,\n",
    "    \"Regression Type\": regression_type,\n",
    "    \"Best Alpha\": best_alpha, \n",
    "    \"Best L1 Ratio\": \"NA\",\n",
    "    \"Variables Used\": len(X_subset.columns),\n",
    "    \"Top 10 Variables\": \", \".join(coef_df['Variable'].head(10).tolist()),\n",
    "    \"Top 10 Coefficients\": \", \".join([f\"{c:.2f}\" for c in coef_df['Coefficient'].head(10).tolist()]),\n",
    "    \"Split\": \"CV-5\",\n",
    "    \"RMSE Mean\": -rmse.mean(),\n",
    "    \"MSE Mean\": -mse.mean(),\n",
    "    \"R2 Mean\": r2.mean()\n",
    "})\n",
    "\n",
    "# Display\n",
    "cumulative_models = pd.DataFrame(records)\n",
    "cumulative_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dba760",
   "metadata": {},
   "source": [
    "### Lasso Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "f8bd012c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.545e+03, tolerance: 4.137e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.046e+03, tolerance: 4.281e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.053e+04, tolerance: 4.558e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.306e+03, tolerance: 4.137e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.302e+04, tolerance: 4.558e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.733e+04, tolerance: 4.558e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.304e+04, tolerance: 4.558e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.822e+03, tolerance: 4.558e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.404e+03, tolerance: 4.558e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.591e+03, tolerance: 4.558e+03\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Regression Type</th>\n",
       "      <th>Best Alpha</th>\n",
       "      <th>Best L1 Ratio</th>\n",
       "      <th>Variables Used</th>\n",
       "      <th>Top 10 Variables</th>\n",
       "      <th>Top 10 Coefficients</th>\n",
       "      <th>Split</th>\n",
       "      <th>RMSE Mean</th>\n",
       "      <th>MSE Mean</th>\n",
       "      <th>R2 Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All_Features_Linear</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>All</td>\n",
       "      <td>CRuns, CAtBat, Hits, AtBat, CRBI, CWalks, Walk...</td>\n",
       "      <td>480.75, -391.04, 337.83, -291.09, 260.69, -213...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>342.139591</td>\n",
       "      <td>121136.310318</td>\n",
       "      <td>0.343495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge_All_Tuned</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>3.393222</td>\n",
       "      <td>NA</td>\n",
       "      <td>All</td>\n",
       "      <td>Hits, AtBat, CRuns, CWalks, CHits, Division_W,...</td>\n",
       "      <td>233.42, -218.94, 203.43, -146.12, 119.93, -118...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>338.640502</td>\n",
       "      <td>118715.693998</td>\n",
       "      <td>0.363510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso_All_Tuned</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>2.222996</td>\n",
       "      <td>NA</td>\n",
       "      <td>All</td>\n",
       "      <td>Hits, AtBat, CRuns, CWalks, CRBI, Division_W, ...</td>\n",
       "      <td>269.91, -249.36, 233.40, -153.72, 122.59, -114...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>339.164091</td>\n",
       "      <td>119077.752512</td>\n",
       "      <td>0.364623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ElasticNet_All_Tuned</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>All</td>\n",
       "      <td>Hits, AtBat, CRuns, Division_W, CWalks, CHits,...</td>\n",
       "      <td>183.90, -168.73, 147.09, -115.34, -114.21, 105...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>338.523418</td>\n",
       "      <td>118776.366833</td>\n",
       "      <td>0.366784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hits_Linear</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>Hits</td>\n",
       "      <td>197.52</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>408.435433</td>\n",
       "      <td>173088.972864</td>\n",
       "      <td>0.122213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hits_Ridge</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>24.420531</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>Hits</td>\n",
       "      <td>180.74</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>407.841429</td>\n",
       "      <td>172580.243054</td>\n",
       "      <td>0.128410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hits_Lasso</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>5.963623</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>Hits</td>\n",
       "      <td>191.55</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>408.373539</td>\n",
       "      <td>173047.782853</td>\n",
       "      <td>0.123640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hits_Elasticnet</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.132571</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hits</td>\n",
       "      <td>174.40</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>407.830061</td>\n",
       "      <td>172569.673986</td>\n",
       "      <td>0.128863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Top5_Linear</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>5</td>\n",
       "      <td>Hits, AtBat, CRBI, CRuns, CWalks</td>\n",
       "      <td>346.11, -207.85, 164.32, 67.36, -2.98</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>346.069484</td>\n",
       "      <td>125502.852876</td>\n",
       "      <td>0.364326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Top5_Ridge</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>2.947052</td>\n",
       "      <td>NA</td>\n",
       "      <td>5</td>\n",
       "      <td>Hits, CRBI, AtBat, CRuns, CWalks</td>\n",
       "      <td>279.81, 153.36, -142.16, 76.24, -2.03</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>344.998216</td>\n",
       "      <td>124956.375184</td>\n",
       "      <td>0.369658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Top5_Lasso</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>1.264855</td>\n",
       "      <td>NA</td>\n",
       "      <td>5</td>\n",
       "      <td>Hits, AtBat, CRBI, CRuns, CWalks</td>\n",
       "      <td>311.42, -172.58, 162.16, 65.29, 0.00</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>345.470227</td>\n",
       "      <td>125285.393348</td>\n",
       "      <td>0.367334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Top5_Elasticnet</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>5</td>\n",
       "      <td>Hits, CRBI, AtBat, CRuns, CWalks</td>\n",
       "      <td>230.78, 143.88, -93.52, 80.66, 1.72</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>344.974241</td>\n",
       "      <td>125057.212316</td>\n",
       "      <td>0.370411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Lin_Num_Cat_Interact</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>11</td>\n",
       "      <td>AtBat_x_Division, Hits_x_Division, Hits, AtBat...</td>\n",
       "      <td>517.14, -489.78, 456.44, -327.22, 286.34, -169...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>355.297221</td>\n",
       "      <td>132054.760135</td>\n",
       "      <td>0.309611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Ridge_Num_Cat_Interact</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>37.275937</td>\n",
       "      <td>NA</td>\n",
       "      <td>11</td>\n",
       "      <td>CRBI, Hits, CRuns, CWalks_x_Division, CWalks, ...</td>\n",
       "      <td>130.58, 114.41, 94.29, -45.72, 35.89, -18.90, ...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>341.543568</td>\n",
       "      <td>121538.755636</td>\n",
       "      <td>0.381395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Lasso_Num_Cat_Interact</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>12.067926</td>\n",
       "      <td>NA</td>\n",
       "      <td>11</td>\n",
       "      <td>CRBI, Hits, CRuns, CRBI_x_Division, CWalks_x_D...</td>\n",
       "      <td>193.06, 130.37, 70.82, -38.78, -36.78, -18.06,...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>345.073718</td>\n",
       "      <td>123856.771800</td>\n",
       "      <td>0.365221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model Regression Type Best Alpha Best L1 Ratio  ... Split   RMSE Mean       MSE Mean   R2 Mean\n",
       "0      All_Features_Linear          Linear         NA            NA  ...  CV-5  342.139591  121136.310318  0.343495\n",
       "1          Ridge_All_Tuned           Ridge   3.393222            NA  ...  CV-5  338.640502  118715.693998  0.363510\n",
       "2          Lasso_All_Tuned           Lasso   2.222996            NA  ...  CV-5  339.164091  119077.752512  0.364623\n",
       "3     ElasticNet_All_Tuned      ElasticNet        0.1          0.75  ...  CV-5  338.523418  118776.366833  0.366784\n",
       "4              Hits_Linear          Linear         NA            NA  ...  CV-5  408.435433  173088.972864  0.122213\n",
       "5               Hits_Ridge           Ridge  24.420531            NA  ...  CV-5  407.841429  172580.243054  0.128410\n",
       "6               Hits_Lasso           Lasso   5.963623            NA  ...  CV-5  408.373539  173047.782853  0.123640\n",
       "7          Hits_Elasticnet      ElasticNet   0.132571             0  ...  CV-5  407.830061  172569.673986  0.128863\n",
       "8              Top5_Linear          Linear         NA            NA  ...  CV-5  346.069484  125502.852876  0.364326\n",
       "9               Top5_Ridge           Ridge   2.947052            NA  ...  CV-5  344.998216  124956.375184  0.369658\n",
       "10              Top5_Lasso           Lasso   1.264855            NA  ...  CV-5  345.470227  125285.393348  0.367334\n",
       "11         Top5_Elasticnet      ElasticNet        0.1          0.75  ...  CV-5  344.974241  125057.212316  0.370411\n",
       "12    Lin_Num_Cat_Interact          Linear         NA            NA  ...  CV-5  355.297221  132054.760135  0.309611\n",
       "13  Ridge_Num_Cat_Interact           Ridge  37.275937            NA  ...  CV-5  341.543568  121538.755636  0.381395\n",
       "14  Lasso_Num_Cat_Interact           Lasso  12.067926            NA  ...  CV-5  345.073718  123856.771800  0.365221\n",
       "\n",
       "[15 rows x 11 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Name\n",
    "model_name = \"Lasso_Num_Cat_Interact\"\n",
    "regression_type = \"Lasso\"  \n",
    "\n",
    "# Features\n",
    "numeric_vars = ['CRuns', 'Hits', 'AtBat', 'CRBI', 'CWalks']\n",
    "cat_var = 'Division'\n",
    "\n",
    "# Select and Subset\n",
    "X_subset = X[numeric_vars + [cat_var]].copy()\n",
    "X_subset['Division_Binary'] = (X_subset['Division'] == 'W').astype(int)\n",
    "\n",
    "# Create interaction\n",
    "X_subset['CRuns_x_Division'] = X_subset['CRuns'] * X_subset['Division_Binary']\n",
    "X_subset['Hits_x_Division'] = X_subset['Hits'] * X_subset['Division_Binary']\n",
    "X_subset['AtBat_x_Division'] = X_subset['AtBat'] * X_subset['Division_Binary']\n",
    "X_subset['CRBI_x_Division'] = X_subset['CRBI'] * X_subset['Division_Binary']\n",
    "X_subset['CWalks_x_Division'] = X_subset['CWalks'] * X_subset['Division_Binary']\n",
    "\n",
    "# Drop the temporary Division_Binary column\n",
    "X_subset = X_subset.drop(columns=['Division_Binary'])\n",
    "\n",
    "# Pipeline\n",
    "pipe = Pipeline([\n",
    "    (\"preprocess\", ct),\n",
    "    (\"lasso\", Lasso()) \n",
    "])\n",
    "\n",
    "# GridSearchCV \n",
    "param_grid = {'lasso__alpha': np.logspace(-1, 2, 50)} \n",
    "gscv = GridSearchCV(pipe, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "gscv.fit(X_subset, y)\n",
    "\n",
    "# Add best model to Library\n",
    "model_library[model_name] = gscv.best_estimator_\n",
    "\n",
    "# Get best alpha\n",
    "best_alpha = gscv.best_params_['lasso__alpha']\n",
    "\n",
    "# Get top 10 coefficients\n",
    "feature_names = gscv.best_estimator_.named_steps['preprocess'].get_feature_names_out()\n",
    "coefficients = gscv.best_estimator_.named_steps['lasso'].coef_\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    'Variable': feature_names,\n",
    "    'Coefficient': coefficients\n",
    "}).sort_values('Coefficient', key=abs, ascending=False).head(10)\n",
    "\n",
    "# Metrics Calculation using best model\n",
    "rmse = cross_val_score(gscv.best_estimator_, X_subset, y, cv=5, scoring='neg_root_mean_squared_error')\n",
    "mse = cross_val_score(gscv.best_estimator_, X_subset, y, cv=5, scoring='neg_mean_squared_error')\n",
    "r2 = cross_val_score(gscv.best_estimator_, X_subset, y, cv=5, scoring='r2')\n",
    "\n",
    "# Metrics Storage \n",
    "records.append({\n",
    "    \"Model\": model_name,\n",
    "    \"Regression Type\": regression_type,\n",
    "    \"Best Alpha\": best_alpha, \n",
    "    \"Best L1 Ratio\": \"NA\",\n",
    "    \"Variables Used\": len(X_subset.columns),\n",
    "    \"Top 10 Variables\": \", \".join(coef_df['Variable'].head(10).tolist()),\n",
    "    \"Top 10 Coefficients\": \", \".join([f\"{c:.2f}\" for c in coef_df['Coefficient'].head(10).tolist()]),\n",
    "    \"Split\": \"CV-5\",\n",
    "    \"RMSE Mean\": -rmse.mean(),\n",
    "    \"MSE Mean\": -mse.mean(),\n",
    "    \"R2 Mean\": r2.mean()\n",
    "})\n",
    "\n",
    "# Display\n",
    "cumulative_models = pd.DataFrame(records)\n",
    "cumulative_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb18eb21",
   "metadata": {},
   "source": [
    "### Elasticnet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "9d441bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.317e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.051e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.231e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.025e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.256e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.545e+03, tolerance: 4.137e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.046e+03, tolerance: 4.281e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.053e+04, tolerance: 4.558e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.328e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.057e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.239e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.035e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.264e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.306e+03, tolerance: 4.137e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.302e+04, tolerance: 4.558e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.339e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.063e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.247e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.044e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.272e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.733e+04, tolerance: 4.558e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.351e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.070e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.256e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.055e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.282e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.304e+04, tolerance: 4.558e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.364e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.078e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.266e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.066e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.292e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.822e+03, tolerance: 4.558e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.378e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.086e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.276e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.078e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.303e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.404e+03, tolerance: 4.558e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.393e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.096e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.287e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.091e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.315e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.591e+03, tolerance: 4.558e+03\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.409e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.106e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.299e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.105e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.329e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.426e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.117e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.312e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.120e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.343e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.444e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.129e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.326e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.137e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.360e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.464e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.142e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.341e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.155e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.377e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.485e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.157e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.357e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.175e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.396e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.508e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.172e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.375e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.196e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.417e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.532e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.189e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.393e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.220e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.439e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.558e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.207e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.414e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.245e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.463e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.586e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.226e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.435e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.272e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.489e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.615e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.246e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.458e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.301e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.517e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.645e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.267e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.482e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.331e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.546e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.677e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.290e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.507e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.364e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.577e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.710e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.313e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.533e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.398e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.609e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.744e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.337e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.560e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.434e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.642e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.778e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.362e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.587e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.470e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.676e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.813e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.387e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.615e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.508e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.711e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.849e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.412e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.644e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.546e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.746e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.884e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.438e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.672e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.584e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.781e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.918e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.463e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.700e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.623e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.816e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.952e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.488e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.727e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.661e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.851e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.985e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.513e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.754e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.698e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.885e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.016e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.537e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.780e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.734e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.917e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.047e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.560e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.805e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.769e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.949e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.075e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.581e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.829e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.802e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.978e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.102e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.602e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.851e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.834e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.007e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.127e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.622e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.872e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.864e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.033e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.150e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.640e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.892e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.891e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.058e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.172e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.656e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.910e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.917e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.081e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.192e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.672e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.927e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.941e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.102e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.210e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.686e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.942e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.962e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.121e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.226e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.699e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.956e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.982e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.139e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.241e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.711e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.969e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.000e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.155e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.254e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.722e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.981e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.016e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.169e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.266e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.731e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.991e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.031e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.182e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.276e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.740e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.000e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.044e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.194e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.286e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.747e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.008e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.056e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.204e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.294e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.754e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.016e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.066e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.213e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.301e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.760e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.022e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.075e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.221e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.308e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.765e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.028e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.083e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.228e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.314e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.770e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.033e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.091e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.235e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.319e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.774e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.037e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.097e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.240e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.323e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.778e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.041e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.102e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.245e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.327e+07, tolerance: 4.708e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.781e+07, tolerance: 3.606e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.045e+07, tolerance: 4.137e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.107e+07, tolerance: 4.281e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.250e+07, tolerance: 4.558e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Regression Type</th>\n",
       "      <th>Best Alpha</th>\n",
       "      <th>Best L1 Ratio</th>\n",
       "      <th>Variables Used</th>\n",
       "      <th>Top 10 Variables</th>\n",
       "      <th>Top 10 Coefficients</th>\n",
       "      <th>Split</th>\n",
       "      <th>RMSE Mean</th>\n",
       "      <th>MSE Mean</th>\n",
       "      <th>R2 Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All_Features_Linear</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>All</td>\n",
       "      <td>CRuns, CAtBat, Hits, AtBat, CRBI, CWalks, Walk...</td>\n",
       "      <td>480.75, -391.04, 337.83, -291.09, 260.69, -213...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>342.139591</td>\n",
       "      <td>121136.310318</td>\n",
       "      <td>0.343495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge_All_Tuned</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>3.393222</td>\n",
       "      <td>NA</td>\n",
       "      <td>All</td>\n",
       "      <td>Hits, AtBat, CRuns, CWalks, CHits, Division_W,...</td>\n",
       "      <td>233.42, -218.94, 203.43, -146.12, 119.93, -118...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>338.640502</td>\n",
       "      <td>118715.693998</td>\n",
       "      <td>0.363510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso_All_Tuned</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>2.222996</td>\n",
       "      <td>NA</td>\n",
       "      <td>All</td>\n",
       "      <td>Hits, AtBat, CRuns, CWalks, CRBI, Division_W, ...</td>\n",
       "      <td>269.91, -249.36, 233.40, -153.72, 122.59, -114...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>339.164091</td>\n",
       "      <td>119077.752512</td>\n",
       "      <td>0.364623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ElasticNet_All_Tuned</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>All</td>\n",
       "      <td>Hits, AtBat, CRuns, Division_W, CWalks, CHits,...</td>\n",
       "      <td>183.90, -168.73, 147.09, -115.34, -114.21, 105...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>338.523418</td>\n",
       "      <td>118776.366833</td>\n",
       "      <td>0.366784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hits_Linear</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>Hits</td>\n",
       "      <td>197.52</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>408.435433</td>\n",
       "      <td>173088.972864</td>\n",
       "      <td>0.122213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hits_Ridge</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>24.420531</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>Hits</td>\n",
       "      <td>180.74</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>407.841429</td>\n",
       "      <td>172580.243054</td>\n",
       "      <td>0.128410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hits_Lasso</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>5.963623</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>Hits</td>\n",
       "      <td>191.55</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>408.373539</td>\n",
       "      <td>173047.782853</td>\n",
       "      <td>0.123640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hits_Elasticnet</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.132571</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hits</td>\n",
       "      <td>174.40</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>407.830061</td>\n",
       "      <td>172569.673986</td>\n",
       "      <td>0.128863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Top5_Linear</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>5</td>\n",
       "      <td>Hits, AtBat, CRBI, CRuns, CWalks</td>\n",
       "      <td>346.11, -207.85, 164.32, 67.36, -2.98</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>346.069484</td>\n",
       "      <td>125502.852876</td>\n",
       "      <td>0.364326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Top5_Ridge</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>2.947052</td>\n",
       "      <td>NA</td>\n",
       "      <td>5</td>\n",
       "      <td>Hits, CRBI, AtBat, CRuns, CWalks</td>\n",
       "      <td>279.81, 153.36, -142.16, 76.24, -2.03</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>344.998216</td>\n",
       "      <td>124956.375184</td>\n",
       "      <td>0.369658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Top5_Lasso</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>1.264855</td>\n",
       "      <td>NA</td>\n",
       "      <td>5</td>\n",
       "      <td>Hits, AtBat, CRBI, CRuns, CWalks</td>\n",
       "      <td>311.42, -172.58, 162.16, 65.29, 0.00</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>345.470227</td>\n",
       "      <td>125285.393348</td>\n",
       "      <td>0.367334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Top5_Elasticnet</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>5</td>\n",
       "      <td>Hits, CRBI, AtBat, CRuns, CWalks</td>\n",
       "      <td>230.78, 143.88, -93.52, 80.66, 1.72</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>344.974241</td>\n",
       "      <td>125057.212316</td>\n",
       "      <td>0.370411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Lin_Num_Cat_Interact</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>11</td>\n",
       "      <td>AtBat_x_Division, Hits_x_Division, Hits, AtBat...</td>\n",
       "      <td>517.14, -489.78, 456.44, -327.22, 286.34, -169...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>355.297221</td>\n",
       "      <td>132054.760135</td>\n",
       "      <td>0.309611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Ridge_Num_Cat_Interact</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>37.275937</td>\n",
       "      <td>NA</td>\n",
       "      <td>11</td>\n",
       "      <td>CRBI, Hits, CRuns, CWalks_x_Division, CWalks, ...</td>\n",
       "      <td>130.58, 114.41, 94.29, -45.72, 35.89, -18.90, ...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>341.543568</td>\n",
       "      <td>121538.755636</td>\n",
       "      <td>0.381395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Lasso_Num_Cat_Interact</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>12.067926</td>\n",
       "      <td>NA</td>\n",
       "      <td>11</td>\n",
       "      <td>CRBI, Hits, CRuns, CRBI_x_Division, CWalks_x_D...</td>\n",
       "      <td>193.06, 130.37, 70.82, -38.78, -36.78, -18.06,...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>345.073718</td>\n",
       "      <td>123856.771800</td>\n",
       "      <td>0.365221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ElasticNet_Num_Cat_Interact</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.625055</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11</td>\n",
       "      <td>CRBI, Hits, CRuns, CWalks_x_Division, CWalks, ...</td>\n",
       "      <td>126.74, 110.73, 93.12, -43.94, 37.30, 20.32, -...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>341.563306</td>\n",
       "      <td>121501.859063</td>\n",
       "      <td>0.380932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model Regression Type Best Alpha Best L1 Ratio  ... Split   RMSE Mean       MSE Mean   R2 Mean\n",
       "0           All_Features_Linear          Linear         NA            NA  ...  CV-5  342.139591  121136.310318  0.343495\n",
       "1               Ridge_All_Tuned           Ridge   3.393222            NA  ...  CV-5  338.640502  118715.693998  0.363510\n",
       "2               Lasso_All_Tuned           Lasso   2.222996            NA  ...  CV-5  339.164091  119077.752512  0.364623\n",
       "3          ElasticNet_All_Tuned      ElasticNet        0.1          0.75  ...  CV-5  338.523418  118776.366833  0.366784\n",
       "4                   Hits_Linear          Linear         NA            NA  ...  CV-5  408.435433  173088.972864  0.122213\n",
       "5                    Hits_Ridge           Ridge  24.420531            NA  ...  CV-5  407.841429  172580.243054  0.128410\n",
       "6                    Hits_Lasso           Lasso   5.963623            NA  ...  CV-5  408.373539  173047.782853  0.123640\n",
       "7               Hits_Elasticnet      ElasticNet   0.132571             0  ...  CV-5  407.830061  172569.673986  0.128863\n",
       "8                   Top5_Linear          Linear         NA            NA  ...  CV-5  346.069484  125502.852876  0.364326\n",
       "9                    Top5_Ridge           Ridge   2.947052            NA  ...  CV-5  344.998216  124956.375184  0.369658\n",
       "10                   Top5_Lasso           Lasso   1.264855            NA  ...  CV-5  345.470227  125285.393348  0.367334\n",
       "11              Top5_Elasticnet      ElasticNet        0.1          0.75  ...  CV-5  344.974241  125057.212316  0.370411\n",
       "12         Lin_Num_Cat_Interact          Linear         NA            NA  ...  CV-5  355.297221  132054.760135  0.309611\n",
       "13       Ridge_Num_Cat_Interact           Ridge  37.275937            NA  ...  CV-5  341.543568  121538.755636  0.381395\n",
       "14       Lasso_Num_Cat_Interact           Lasso  12.067926            NA  ...  CV-5  345.073718  123856.771800  0.365221\n",
       "15  ElasticNet_Num_Cat_Interact      ElasticNet   0.625055          0.75  ...  CV-5  341.563306  121501.859063  0.380932\n",
       "\n",
       "[16 rows x 11 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Name\n",
    "model_name = \"ElasticNet_Num_Cat_Interact\"  \n",
    "regression_type = \"ElasticNet\" \n",
    "\n",
    "# Features\n",
    "numeric_vars = ['CRuns', 'Hits', 'AtBat', 'CRBI', 'CWalks']\n",
    "cat_var = 'Division'\n",
    "\n",
    "# Select and Subset\n",
    "X_subset = X[numeric_vars + [cat_var]].copy()\n",
    "X_subset['Division_Binary'] = (X_subset['Division'] == 'W').astype(int)\n",
    "\n",
    "# Create interaction\n",
    "X_subset['CRuns_x_Division'] = X_subset['CRuns'] * X_subset['Division_Binary']\n",
    "X_subset['Hits_x_Division'] = X_subset['Hits'] * X_subset['Division_Binary']\n",
    "X_subset['AtBat_x_Division'] = X_subset['AtBat'] * X_subset['Division_Binary']\n",
    "X_subset['CRBI_x_Division'] = X_subset['CRBI'] * X_subset['Division_Binary']\n",
    "X_subset['CWalks_x_Division'] = X_subset['CWalks'] * X_subset['Division_Binary']\n",
    "\n",
    "# Drop the temporary Division_Binary column\n",
    "X_subset = X_subset.drop(columns=['Division_Binary'])\n",
    "\n",
    "# Pipeline with ElasticNet\n",
    "pipe = Pipeline([\n",
    "    (\"preprocess\", ct),\n",
    "    (\"elasticnet\", ElasticNet()) \n",
    "])\n",
    "\n",
    "# GridSearchCV \n",
    "param_grid = {\n",
    "    'elasticnet__alpha': np.logspace(-1, 2, 50),\n",
    "    'elasticnet__l1_ratio': [0, 0.25, 0.5, 0.75, 1]\n",
    "} \n",
    "gscv = GridSearchCV(pipe, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "gscv.fit(X_subset, y)\n",
    "\n",
    "# Add best model to Library\n",
    "model_library[model_name] = gscv.best_estimator_\n",
    "\n",
    "# Get best Alpha and L1\n",
    "best_alpha = gscv.best_params_['elasticnet__alpha'] \n",
    "best_l1_ratio = gscv.best_params_['elasticnet__l1_ratio'] \n",
    "\n",
    "# Get top 10 coefficients\n",
    "feature_names = gscv.best_estimator_.named_steps['preprocess'].get_feature_names_out()\n",
    "coefficients = gscv.best_estimator_.named_steps['elasticnet'].coef_\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    'Variable': feature_names,\n",
    "    'Coefficient': coefficients\n",
    "}).sort_values('Coefficient', key=abs, ascending=False).head(10)\n",
    "\n",
    "# Metrics Calculation using best model\n",
    "rmse = cross_val_score(gscv.best_estimator_, X_subset, y, cv=5, scoring='neg_root_mean_squared_error')\n",
    "mse = cross_val_score(gscv.best_estimator_, X_subset, y, cv=5, scoring='neg_mean_squared_error')\n",
    "r2 = cross_val_score(gscv.best_estimator_, X_subset, y, cv=5, scoring='r2')\n",
    "\n",
    "# Metrics Storage \n",
    "records.append({\n",
    "    \"Model\": model_name,\n",
    "    \"Regression Type\": regression_type,\n",
    "    \"Best Alpha\": best_alpha,\n",
    "    \"Best L1 Ratio\": best_l1_ratio,\n",
    "    \"Variables Used\": len(X_subset.columns),\n",
    "    \"Top 10 Variables\": \", \".join(coef_df['Variable'].head(10).tolist()),\n",
    "    \"Top 10 Coefficients\": \", \".join([f\"{c:.2f}\" for c in coef_df['Coefficient'].head(10).tolist()]),\n",
    "    \"Split\": \"CV-5\",\n",
    "    \"RMSE Mean\": -rmse.mean(),\n",
    "    \"MSE Mean\": -mse.mean(),\n",
    "    \"R2 Mean\": r2.mean()\n",
    "})\n",
    "\n",
    "# Display\n",
    "cumulative_models = pd.DataFrame(records)\n",
    "cumulative_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabefecc",
   "metadata": {},
   "source": [
    "### Interpretation \n",
    "\n",
    "Elastic Net Takes the lead again "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df34e4fc",
   "metadata": {},
   "source": [
    "# Part III. Discussion\n",
    "\n",
    "## A. Ridge\n",
    "\n",
    "Compare your Ridge models with your ordinary regression models. How did your coefficients compare? Why does this make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "a16d822a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Regression Type</th>\n",
       "      <th>Best Alpha</th>\n",
       "      <th>Best L1 Ratio</th>\n",
       "      <th>Variables Used</th>\n",
       "      <th>Top 10 Variables</th>\n",
       "      <th>Top 10 Coefficients</th>\n",
       "      <th>Split</th>\n",
       "      <th>RMSE Mean</th>\n",
       "      <th>MSE Mean</th>\n",
       "      <th>R2 Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All_Features_Linear</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>All</td>\n",
       "      <td>CRuns, CAtBat, Hits, AtBat, CRBI, CWalks, Walk...</td>\n",
       "      <td>480.75, -391.04, 337.83, -291.09, 260.69, -213...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>342.139591</td>\n",
       "      <td>121136.310318</td>\n",
       "      <td>0.343495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hits_Linear</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>Hits</td>\n",
       "      <td>197.52</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>408.435433</td>\n",
       "      <td>173088.972864</td>\n",
       "      <td>0.122213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Top5_Linear</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>5</td>\n",
       "      <td>Hits, AtBat, CRBI, CRuns, CWalks</td>\n",
       "      <td>346.11, -207.85, 164.32, 67.36, -2.98</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>346.069484</td>\n",
       "      <td>125502.852876</td>\n",
       "      <td>0.364326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Lin_Num_Cat_Interact</td>\n",
       "      <td>Linear</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>11</td>\n",
       "      <td>AtBat_x_Division, Hits_x_Division, Hits, AtBat...</td>\n",
       "      <td>517.14, -489.78, 456.44, -327.22, 286.34, -169...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>355.297221</td>\n",
       "      <td>132054.760135</td>\n",
       "      <td>0.309611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge_All_Tuned</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>3.393222</td>\n",
       "      <td>NA</td>\n",
       "      <td>All</td>\n",
       "      <td>Hits, AtBat, CRuns, CWalks, CHits, Division_W,...</td>\n",
       "      <td>233.42, -218.94, 203.43, -146.12, 119.93, -118...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>338.640502</td>\n",
       "      <td>118715.693998</td>\n",
       "      <td>0.363510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hits_Ridge</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>24.420531</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>Hits</td>\n",
       "      <td>180.74</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>407.841429</td>\n",
       "      <td>172580.243054</td>\n",
       "      <td>0.128410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Top5_Ridge</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>2.947052</td>\n",
       "      <td>NA</td>\n",
       "      <td>5</td>\n",
       "      <td>Hits, CRBI, AtBat, CRuns, CWalks</td>\n",
       "      <td>279.81, 153.36, -142.16, 76.24, -2.03</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>344.998216</td>\n",
       "      <td>124956.375184</td>\n",
       "      <td>0.369658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Ridge_Num_Cat_Interact</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>37.275937</td>\n",
       "      <td>NA</td>\n",
       "      <td>11</td>\n",
       "      <td>CRBI, Hits, CRuns, CWalks_x_Division, CWalks, ...</td>\n",
       "      <td>130.58, 114.41, 94.29, -45.72, 35.89, -18.90, ...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>341.543568</td>\n",
       "      <td>121538.755636</td>\n",
       "      <td>0.381395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model Regression Type Best Alpha Best L1 Ratio  ... Split   RMSE Mean       MSE Mean   R2 Mean\n",
       "0      All_Features_Linear          Linear         NA            NA  ...  CV-5  342.139591  121136.310318  0.343495\n",
       "4              Hits_Linear          Linear         NA            NA  ...  CV-5  408.435433  173088.972864  0.122213\n",
       "8              Top5_Linear          Linear         NA            NA  ...  CV-5  346.069484  125502.852876  0.364326\n",
       "12    Lin_Num_Cat_Interact          Linear         NA            NA  ...  CV-5  355.297221  132054.760135  0.309611\n",
       "1          Ridge_All_Tuned           Ridge   3.393222            NA  ...  CV-5  338.640502  118715.693998  0.363510\n",
       "5               Hits_Ridge           Ridge  24.420531            NA  ...  CV-5  407.841429  172580.243054  0.128410\n",
       "9               Top5_Ridge           Ridge   2.947052            NA  ...  CV-5  344.998216  124956.375184  0.369658\n",
       "13  Ridge_Num_Cat_Interact           Ridge  37.275937            NA  ...  CV-5  341.543568  121538.755636  0.381395\n",
       "\n",
       "[8 rows x 11 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumulative_models[cumulative_models['Regression Type'].isin(['Linear', 'Ridge'])].sort_values('Regression Type')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9419947",
   "metadata": {},
   "source": [
    "Coefficients for Ridge models are on a whole smaller than the linear regression models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210ff9d7",
   "metadata": {},
   "source": [
    "## B. LASSO\n",
    "\n",
    "Compare your LASSO model in I with your three LASSO models in II. Did you get the same $\\lambda$ results? Why does this make sense? Did you get the same MSEs? Why does this make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "81af8e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Regression Type</th>\n",
       "      <th>Best Alpha</th>\n",
       "      <th>Best L1 Ratio</th>\n",
       "      <th>Variables Used</th>\n",
       "      <th>Top 10 Variables</th>\n",
       "      <th>Top 10 Coefficients</th>\n",
       "      <th>Split</th>\n",
       "      <th>RMSE Mean</th>\n",
       "      <th>MSE Mean</th>\n",
       "      <th>R2 Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso_All_Tuned</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>2.222996</td>\n",
       "      <td>NA</td>\n",
       "      <td>All</td>\n",
       "      <td>Hits, AtBat, CRuns, CWalks, CRBI, Division_W, ...</td>\n",
       "      <td>269.91, -249.36, 233.40, -153.72, 122.59, -114...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>339.164091</td>\n",
       "      <td>119077.752512</td>\n",
       "      <td>0.364623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hits_Lasso</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>5.963623</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>Hits</td>\n",
       "      <td>191.55</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>408.373539</td>\n",
       "      <td>173047.782853</td>\n",
       "      <td>0.123640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Top5_Lasso</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>1.264855</td>\n",
       "      <td>NA</td>\n",
       "      <td>5</td>\n",
       "      <td>Hits, AtBat, CRBI, CRuns, CWalks</td>\n",
       "      <td>311.42, -172.58, 162.16, 65.29, 0.00</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>345.470227</td>\n",
       "      <td>125285.393348</td>\n",
       "      <td>0.367334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Lasso_Num_Cat_Interact</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>12.067926</td>\n",
       "      <td>NA</td>\n",
       "      <td>11</td>\n",
       "      <td>CRBI, Hits, CRuns, CRBI_x_Division, CWalks_x_D...</td>\n",
       "      <td>193.06, 130.37, 70.82, -38.78, -36.78, -18.06,...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>345.073718</td>\n",
       "      <td>123856.771800</td>\n",
       "      <td>0.365221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model Regression Type Best Alpha Best L1 Ratio  ... Split   RMSE Mean       MSE Mean   R2 Mean\n",
       "2          Lasso_All_Tuned           Lasso   2.222996            NA  ...  CV-5  339.164091  119077.752512  0.364623\n",
       "6               Hits_Lasso           Lasso   5.963623            NA  ...  CV-5  408.373539  173047.782853  0.123640\n",
       "10              Top5_Lasso           Lasso   1.264855            NA  ...  CV-5  345.470227  125285.393348  0.367334\n",
       "14  Lasso_Num_Cat_Interact           Lasso  12.067926            NA  ...  CV-5  345.073718  123856.771800  0.365221\n",
       "\n",
       "[4 rows x 11 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumulative_models[cumulative_models['Regression Type'] == 'Lasso']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e537857",
   "metadata": {},
   "source": [
    "While the latter Lasso models are not more than 10 Alpha units differengt than the First Lasso I would comfortably say they are all different. This makes sense as changing the number of features considered will impact alpha. The higher the features the lower the MSE as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc976f7b",
   "metadata": {},
   "source": [
    "## C. Elastic Net\n",
    "\n",
    "Compare your MSEs for the Elastic Net models with those for the Ridge and LASSO models. Why does it make sense that Elastic Net always \"wins\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "672545de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Regression Type</th>\n",
       "      <th>Best Alpha</th>\n",
       "      <th>Best L1 Ratio</th>\n",
       "      <th>Variables Used</th>\n",
       "      <th>Top 10 Variables</th>\n",
       "      <th>Top 10 Coefficients</th>\n",
       "      <th>Split</th>\n",
       "      <th>RMSE Mean</th>\n",
       "      <th>MSE Mean</th>\n",
       "      <th>R2 Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ElasticNet_All_Tuned</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>All</td>\n",
       "      <td>Hits, AtBat, CRuns, Division_W, CWalks, CHits,...</td>\n",
       "      <td>183.90, -168.73, 147.09, -115.34, -114.21, 105...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>338.523418</td>\n",
       "      <td>118776.366833</td>\n",
       "      <td>0.366784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hits_Elasticnet</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.132571</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hits</td>\n",
       "      <td>174.40</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>407.830061</td>\n",
       "      <td>172569.673986</td>\n",
       "      <td>0.128863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Top5_Elasticnet</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>5</td>\n",
       "      <td>Hits, CRBI, AtBat, CRuns, CWalks</td>\n",
       "      <td>230.78, 143.88, -93.52, 80.66, 1.72</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>344.974241</td>\n",
       "      <td>125057.212316</td>\n",
       "      <td>0.370411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ElasticNet_Num_Cat_Interact</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.625055</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11</td>\n",
       "      <td>CRBI, Hits, CRuns, CWalks_x_Division, CWalks, ...</td>\n",
       "      <td>126.74, 110.73, 93.12, -43.94, 37.30, 20.32, -...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>341.563306</td>\n",
       "      <td>121501.859063</td>\n",
       "      <td>0.380932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso_All_Tuned</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>2.222996</td>\n",
       "      <td>NA</td>\n",
       "      <td>All</td>\n",
       "      <td>Hits, AtBat, CRuns, CWalks, CRBI, Division_W, ...</td>\n",
       "      <td>269.91, -249.36, 233.40, -153.72, 122.59, -114...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>339.164091</td>\n",
       "      <td>119077.752512</td>\n",
       "      <td>0.364623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hits_Lasso</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>5.963623</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>Hits</td>\n",
       "      <td>191.55</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>408.373539</td>\n",
       "      <td>173047.782853</td>\n",
       "      <td>0.123640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Top5_Lasso</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>1.264855</td>\n",
       "      <td>NA</td>\n",
       "      <td>5</td>\n",
       "      <td>Hits, AtBat, CRBI, CRuns, CWalks</td>\n",
       "      <td>311.42, -172.58, 162.16, 65.29, 0.00</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>345.470227</td>\n",
       "      <td>125285.393348</td>\n",
       "      <td>0.367334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Lasso_Num_Cat_Interact</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>12.067926</td>\n",
       "      <td>NA</td>\n",
       "      <td>11</td>\n",
       "      <td>CRBI, Hits, CRuns, CRBI_x_Division, CWalks_x_D...</td>\n",
       "      <td>193.06, 130.37, 70.82, -38.78, -36.78, -18.06,...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>345.073718</td>\n",
       "      <td>123856.771800</td>\n",
       "      <td>0.365221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge_All_Tuned</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>3.393222</td>\n",
       "      <td>NA</td>\n",
       "      <td>All</td>\n",
       "      <td>Hits, AtBat, CRuns, CWalks, CHits, Division_W,...</td>\n",
       "      <td>233.42, -218.94, 203.43, -146.12, 119.93, -118...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>338.640502</td>\n",
       "      <td>118715.693998</td>\n",
       "      <td>0.363510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hits_Ridge</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>24.420531</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>Hits</td>\n",
       "      <td>180.74</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>407.841429</td>\n",
       "      <td>172580.243054</td>\n",
       "      <td>0.128410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Top5_Ridge</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>2.947052</td>\n",
       "      <td>NA</td>\n",
       "      <td>5</td>\n",
       "      <td>Hits, CRBI, AtBat, CRuns, CWalks</td>\n",
       "      <td>279.81, 153.36, -142.16, 76.24, -2.03</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>344.998216</td>\n",
       "      <td>124956.375184</td>\n",
       "      <td>0.369658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Ridge_Num_Cat_Interact</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>37.275937</td>\n",
       "      <td>NA</td>\n",
       "      <td>11</td>\n",
       "      <td>CRBI, Hits, CRuns, CWalks_x_Division, CWalks, ...</td>\n",
       "      <td>130.58, 114.41, 94.29, -45.72, 35.89, -18.90, ...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>341.543568</td>\n",
       "      <td>121538.755636</td>\n",
       "      <td>0.381395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model Regression Type Best Alpha Best L1 Ratio  ... Split   RMSE Mean       MSE Mean   R2 Mean\n",
       "3          ElasticNet_All_Tuned      ElasticNet        0.1          0.75  ...  CV-5  338.523418  118776.366833  0.366784\n",
       "7               Hits_Elasticnet      ElasticNet   0.132571             0  ...  CV-5  407.830061  172569.673986  0.128863\n",
       "11              Top5_Elasticnet      ElasticNet        0.1          0.75  ...  CV-5  344.974241  125057.212316  0.370411\n",
       "15  ElasticNet_Num_Cat_Interact      ElasticNet   0.625055          0.75  ...  CV-5  341.563306  121501.859063  0.380932\n",
       "2               Lasso_All_Tuned           Lasso   2.222996            NA  ...  CV-5  339.164091  119077.752512  0.364623\n",
       "6                    Hits_Lasso           Lasso   5.963623            NA  ...  CV-5  408.373539  173047.782853  0.123640\n",
       "10                   Top5_Lasso           Lasso   1.264855            NA  ...  CV-5  345.470227  125285.393348  0.367334\n",
       "14       Lasso_Num_Cat_Interact           Lasso  12.067926            NA  ...  CV-5  345.073718  123856.771800  0.365221\n",
       "1               Ridge_All_Tuned           Ridge   3.393222            NA  ...  CV-5  338.640502  118715.693998  0.363510\n",
       "5                    Hits_Ridge           Ridge  24.420531            NA  ...  CV-5  407.841429  172580.243054  0.128410\n",
       "9                    Top5_Ridge           Ridge   2.947052            NA  ...  CV-5  344.998216  124956.375184  0.369658\n",
       "13       Ridge_Num_Cat_Interact           Ridge  37.275937            NA  ...  CV-5  341.543568  121538.755636  0.381395\n",
       "\n",
       "[12 rows x 11 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumulative_models[cumulative_models['Regression Type'].isin(['ElasticNet', 'Ridge', 'Lasso'])].sort_values('Regression Type')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96b0694",
   "metadata": {},
   "source": [
    "Elastic Net makes sense in that it won because it was more tuned than the other model as both Alpha and L1 were tested "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b36f90",
   "metadata": {},
   "source": [
    "# Part IV: Final Model\n",
    "\n",
    "Fit your final best pipeline on the full dataset, and summarize your results in a few short sentences and a plot.\n",
    "\n",
    "\"Best\" is chosen by lowest MSE Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "5fbb3398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Regression Type</th>\n",
       "      <th>Best Alpha</th>\n",
       "      <th>Best L1 Ratio</th>\n",
       "      <th>Variables Used</th>\n",
       "      <th>Top 10 Variables</th>\n",
       "      <th>Top 10 Coefficients</th>\n",
       "      <th>Split</th>\n",
       "      <th>RMSE Mean</th>\n",
       "      <th>MSE Mean</th>\n",
       "      <th>R2 Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Ridge_Num_Cat_Interact</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>37.275937</td>\n",
       "      <td>NA</td>\n",
       "      <td>11</td>\n",
       "      <td>CRBI, Hits, CRuns, CWalks_x_Division, CWalks, ...</td>\n",
       "      <td>130.58, 114.41, 94.29, -45.72, 35.89, -18.90, ...</td>\n",
       "      <td>CV-5</td>\n",
       "      <td>341.543568</td>\n",
       "      <td>121538.755636</td>\n",
       "      <td>0.381395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model Regression Type Best Alpha Best L1 Ratio  ... Split   RMSE Mean       MSE Mean   R2 Mean\n",
       "13  Ridge_Num_Cat_Interact           Ridge  37.275937            NA  ...  CV-5  341.543568  121538.755636  0.381395\n",
       "\n",
       "[1 rows x 11 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumulative_models.sort_values('R2 Mean', ascending=False).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "eaa4d7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model: Ridge_Num_Cat_Interact\n",
      "R Score: 0.462072\n",
      "MSE: 109056.401201\n"
     ]
    }
   ],
   "source": [
    "# Features\n",
    "numeric_vars = ['CRuns', 'Hits', 'AtBat', 'CRBI', 'CWalks']\n",
    "cat_var = 'Division'\n",
    "\n",
    "# Select and Subset\n",
    "X_final = X[numeric_vars + [cat_var]].copy()\n",
    "X_final['Division_Binary'] = (X_final['Division'] == 'W').astype(int)\n",
    "\n",
    "# Create interaction\n",
    "X_final['CRuns_x_Division'] = X_final['CRuns'] * X_final['Division_Binary']\n",
    "X_final['Hits_x_Division'] = X_final['Hits'] * X_final['Division_Binary']\n",
    "X_final['AtBat_x_Division'] = X_final['AtBat'] * X_final['Division_Binary']\n",
    "X_final['CRBI_x_Division'] = X_final['CRBI'] * X_final['Division_Binary']\n",
    "X_final['CWalks_x_Division'] = X_final['CWalks'] * X_final['Division_Binary']\n",
    "\n",
    "# Drop temporary column\n",
    "X_final = X_final.drop(columns=['Division_Binary'])\n",
    "\n",
    "# Fit the model \n",
    "best_pipe = model_library[\"Ridge_Num_Cat_Interact\"]\n",
    "best_pipe.fit(X_final, y)\n",
    "\n",
    "# Generate predictions\n",
    "y_pred = best_pipe.predict(X_final)\n",
    "\n",
    "print(\"Final Model: Ridge_Num_Cat_Interact\")\n",
    "print(f\"R Score: {best_pipe.score(X_final, y):f}\")\n",
    "print(f\"MSE: {((y - y_pred)**2).mean():f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b24528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare data for plotting\n",
    "df_plot = pd.DataFrame({\n",
    "    'Actual_Salary': y,\n",
    "    'Predicted_Salary': y_pred,\n",
    "    'Division': X['Division']\n",
    "})\n",
    "\n",
    "# Plot\n",
    "plot = (\n",
    "    p9.ggplot(df_plot, p9.aes(x='Actual_Salary', y='Predicted_Salary'))\n",
    "    + p9.geom_point(p9.aes(color='Division'), alpha=0.6, size=2)\n",
    "    + p9.geom_abline(intercept=0, slope=1, color='red', linetype='dashed', size=1)\n",
    "    + p9.labs(\n",
    "        title='Ridge Regression: Predicted vs Actual Salary (with Interactions)',\n",
    "        x='Actual Salary (thousands)',\n",
    "        y='Predicted Salary (thousands)'\n",
    "    )\n",
    "    + p9.scale_color_manual(values=['#1f77b4', '#ff7f0e'])\n",
    "    + p9.theme_minimal()\n",
    "    + p9.theme(figure_size=(8, 6))\n",
    ")\n",
    "\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720220a4",
   "metadata": {},
   "source": [
    "While visually the regression line seems to decently represent the data the final R Score: 0.462072 shows that there is a lot of room left for improvement. Likely this model would benefit from further exploration of quadraic, exponential, or log models. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
